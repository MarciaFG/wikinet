{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..', 'module'))\n",
    "import wiki\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condensed sparse column matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "row = np.array([0, 2, 2, 0, 1, 2])\n",
    "col = np.array([0, 0, 1, 2, 2, 2])\n",
    "sp.sparse.csc_matrix((data, (row, col)), shape=(3, 3)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics = ['anatomy', 'biochemistry', 'cognitive science', 'evolutionary biology',\n",
    "#           'genetics', 'immunology', 'molecular biology', 'chemistry', 'biophysics',\n",
    "#           'energy', 'optics', 'earth science', 'geology', 'meteorology']\n",
    "topics = ['earth science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved = '/Users/harangju/Developer/data/wiki/graphs/dated/'\n",
    "networks = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    networks[topic] = wiki.Net()\n",
    "    networks[topic].load_graph(path_saved + topic + '.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(networks[topic].graph.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = networks[topic].graph.graph['tfidf']\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v[:,0].indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v[4,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks[topic].graph.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks[topic].graph.nodes['Biology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core = [n for n in networks[topic].graph.nodes if networks[topic].graph.nodes[n]['core_rb']>.9]\n",
    "core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i,n) for i,n in enumerate(networks[topic].graph.nodes) if networks[topic].graph.nodes[n]['year']<-1800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = v[:,9]\n",
    "vi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(networks[topic].graph.successors('Cryosphere'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(networks[topic].graph.predecessors('Cryosphere'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = networks[topic].graph\n",
    "year_diffs = [[graph.nodes[node]['year'] - graph.nodes[neighbor]['year']\n",
    "               for neighbor in list(graph.successors(node))]# + list(graph.predecessors(node))]\n",
    "              for node in graph.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_diffs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot([y for ys in year_diffs for y in ys])\n",
    "plt.title(topic)\n",
    "plt.xlabel('year difference');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics.pairwise as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = [[smp.cosine_similarity(v[:,list(graph.nodes).index(node)].transpose(),\n",
    "                                       v[:,list(graph.nodes).index(neighbor)].transpose())[0,0]\n",
    "                 for neighbor in list(graph.successors(node))\n",
    "                 if neighbor is not node]# + list(graph.predecessors(node))]\n",
    "                for node in graph.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, std = norm.fit([s for ss in similarities for s in ss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot([s for ss in similarities for s in ss])\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "print(\"Fit results: mu = %.2f,  std = %.2f\" % (mu, std))\n",
    "plt.title(topic)\n",
    "plt.xlabel('cos similarity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSC & networkx operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core = [n for n in networks[topic].graph.nodes if networks[topic].graph.nodes[n]['year']<-2000]\n",
    "subgraph = graph.subgraph(core).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = ss.hstack([v[:,list(graph.nodes).index(n)] for n in subgraph.nodes])\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph.add_node('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph.nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "Initialize with core set of nodes.\\\n",
    "For each year,\\\n",
    "initialize an \"baby\" node for each existing node that doesn't already have a baby node,\\\n",
    "mutate tf-idf for each \"baby\" node (including the name),\\\n",
    "and if the \"baby\" node gets a probability drawn from the distribution of similarities (to what?),\n",
    "the \"baby\" node is born."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(x, N_sub=2, N_add=2, idx_pool=None):\n",
    "    \"\"\"Mutates ``tf-idf`` representations & returns a new one.\n",
    "    Selects ``N_sub=10`` words to subtract from ``x``.\n",
    "    Then, selects ``N_add=10`` words to add to ``x``.\n",
    "    If ``idx_pool`` specified as list of indices,\n",
    "    then choose add words from ``idx_pool``.\n",
    "    \"\"\"\n",
    "    idx_remove = np.random.choice(x.indices, size=N_remove, replace=False)\n",
    "    idx_add = []\n",
    "#     if idx_pool:\n",
    "#         while [i for i in idx_add if i in x.indices]:\n",
    "#             idx_add = np.random.choice(idx_pool, size=N_add, replace=False)\n",
    "#     else:\n",
    "    while True:\n",
    "        idx_add = np.random.choice(x.shape[0], size=N_add, replace=False)\n",
    "        if not any([i in x.indices for i in idx_add]): break\n",
    "    idx_x = np.concatenate(([i for i in x.indices if i not in idx_remove],\n",
    "                            np.random.choice(idx_remove, size=N_add)))\n",
    "    idx_y = np.concatenate(([i for i in x.indices if i not in idx_remove],\n",
    "                            idx_add))\n",
    "    idx_0 = np.zeros(len(idx_y), dtype=int)\n",
    "    y = csc_matrix((x[idx_x,0].data, (idx_y,idx_0)),\n",
    "                   shape=x.shape)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(x, n_new_words=25, p_new_word=1, a=0.08, b=0.001, idx_pool=None):\n",
    "    \"\"\"Mutates ``tf-idf`` representations & returns a new one.\n",
    "    \n",
    "    Algorithm\n",
    "    ---------\n",
    "    - Append ``n_new_words`` new words with initial value as 0,\n",
    "        each with probability ``p_new_word``.\n",
    "    - If given ``idx_pool``, only add words from the pool.\n",
    "    - Mutate existing elements ``x_i`` by \n",
    "        norm(1,``a``) * (``x_i`` + norm(0,``b``))\n",
    "    - Zero out negatives.\n",
    "    \"\"\"\n",
    "    idx_pool = idx_pool if idx_pool else x.shape[0]\n",
    "    while True:\n",
    "        idx_add = np.random.choice(idx_pool, size=n_new_words,\n",
    "                                   replace=False)\n",
    "        idx_add = idx_add[np.random.rand(n_new_words)<p_new_word]\n",
    "        if not any([i in x.indices for i in idx_add]): break\n",
    "    idx = np.concatenate((x.indices, idx_add))\n",
    "    data = np.concatenate((x.data, np.zeros(idx_add.size)))\n",
    "    data = np.multiply(data + norm.rvs(scale=b, size=data.size),\n",
    "                       norm.rvs(loc=1, scale=a, size=data.size))\n",
    "    idx = idx[data>0]\n",
    "    data = data[data>0]\n",
    "    y = csc_matrix((data, (idx, np.zeros(idx.shape, dtype=int))),\n",
    "                   shape=x.shape)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as ss\n",
    "from scipy.stats import norm\n",
    "\n",
    "def algorithm(graph):\n",
    "    \"\"\"Grows a new graph with a core set of nodes selected from ``graph``.\n",
    "    Assumes ``graph.graph['tfidf']`` holds a ``scipy.sparse.csc_matrix`` of \n",
    "    tf-idf vectors.\n",
    "    \"\"\"\n",
    "    core = [n for n in graph.nodes if graph.nodes[n]['year'] < -2000]\n",
    "    tfidf = ss.hstack([graph.graph['tfidf'][:,list(graph.nodes).index(n)] for n in core])\n",
    "    subgraph = graph.subgraph(core).copy()\n",
    "    subgraph.graph.clear()\n",
    "    subgraph.name = graph.name + '-graft'\n",
    "    new_graph, new_tfidf = evolve(subgraph, tfidf)\n",
    "    new_graph.graph['tfidf'] = new_tfidf\n",
    "    return new_graph\n",
    "\n",
    "def evolve(graph, tfidf, year_end=2020):\n",
    "    \"\"\"Evolves a graph based on tf-idf representations.\"\"\"\n",
    "    year_start = max([graph.nodes[n]['year'] for n in graph.nodes])+1\n",
    "    seed_nodes = {}\n",
    "    for year in range(year_start, year_start+1):#year_end+1):\n",
    "        for node in graph.nodes:\n",
    "            if node not in seed_nodes.keys():\n",
    "                seed_nodes[node] = tfidf[:,list(graph.nodes).index(node)].copy()\n",
    "        for node, vec in seed_nodes.items():\n",
    "            seed_nodes[node] = mutate(vec)\n",
    "#         vecs = hh.stack([])\n",
    "        # join seeds/crossover\n",
    "        for node, vec in seed_nodes.items():\n",
    "            if False:\n",
    "                graph.add_node(node)\n",
    "                # connect node\n",
    "                tfidf = ss.hstack([tfidf,vec])\n",
    "                seed_nodes[node] = None\n",
    "        print(year, '\\t', seed_nodes, '\\n')\n",
    "    return graph, tfidf\n",
    "\n",
    "def crossover():\n",
    "    pass\n",
    "\n",
    "def mutate(x, a=0.001, b=0.001, idx_pool=None):\n",
    "    \"\"\"Mutates ``tf-idf`` representations & returns a new one.\n",
    "    \n",
    "    Algorithm\n",
    "    ---------\n",
    "    - Mutate existing elements ``x_i`` by \n",
    "        norm(1,``a``) * (``x_i`` + norm(0,``b``))\n",
    "    - Zero out negatives.\n",
    "    - Append new words by how many were deleted.\n",
    "    - If given ``idx_pool``, only add words from the pool.\n",
    "    \"\"\"\n",
    "    data = np.multiply(x.data + norm.rvs(scale=b, size=x.data.size),\n",
    "                       norm.rvs(loc=1, scale=a, size=x.data.size))\n",
    "    n_new_words = (data<=0).sum()\n",
    "    print(n_new_words, end=' ')\n",
    "    idx_pool = idx_pool if idx_pool else x.shape[0]\n",
    "    while True:\n",
    "        idx_add = np.random.choice(idx_pool, size=n_new_words,\n",
    "                                   replace=False)\n",
    "        if not any([i in x.indices for i in idx_add]): break\n",
    "    idx = np.concatenate((x.indices, idx_add))\n",
    "    data = np.concatenate((data, np.median(x.data)*np.ones(idx_add.size)))\n",
    "    idx = idx[data>0]\n",
    "    data = data[data>0]\n",
    "    y = csc_matrix((data, (idx, np.zeros(idx.shape, dtype=int))),\n",
    "                   shape=x.shape)\n",
    "    return y\n",
    "\n",
    "# algorithm(networks[topic].graph).graph\n",
    "x = tfidf[:,1].copy()\n",
    "y = tfidf[:,1].copy()\n",
    "T = 500\n",
    "sim = np.zeros(T)\n",
    "size = np.zeros(T)\n",
    "for i in range(sim.size):\n",
    "    sim[i] = smp.cosine_similarity(x.transpose(),y.transpose())[0,0]\n",
    "    size[i] = y.size\n",
    "    y = mutate(y)\n",
    "plt.figure()\n",
    "sns.lineplot(x=range(sim.size), y=sim)\n",
    "plt.title(graph.name)\n",
    "plt.ylabel('similarity')\n",
    "plt.xlabel('years');\n",
    "plt.figure()\n",
    "sns.lineplot(x=range(sim.size), y=size)\n",
    "plt.title(graph.name)\n",
    "plt.ylabel('size')\n",
    "plt.xlabel('years');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.distplot(graph.graph['tfidf'][:,1].data)\n",
    "plt.title(graph.name + ' before mutation')\n",
    "plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "plt.xlabel('tf-idf values');\n",
    "plt.figure()\n",
    "sns.distplot(y.data)\n",
    "plt.title(graph.name + ' after mutation')\n",
    "plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "plt.xlabel('tf-idf values');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(graph.graph['tfidf'].sum(0))\n",
    "plt.title(graph.name)\n",
    "plt.xlabel('sum of tf-idf weights');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(graph.graph['tfidf'].data)\n",
    "plt.title(graph.name)\n",
    "plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "plt.xlabel('tf-idf values');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    plt.figure()\n",
    "    sns.distplot(graph.graph['tfidf'][:,i].data,\n",
    "                 hist=True, rug=True, kde=False)\n",
    "    plt.title(graph.name)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('tf-idf values');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check after mutation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
