{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..', 'module'))\n",
    "import wiki\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['anatomy', 'biochemistry', 'cognitive science', 'evolutionary biology',\n",
    "          'genetics', 'immunology', 'molecular biology', 'chemistry', 'biophysics',\n",
    "          'energy', 'optics', 'earth science', 'geology', 'meteorology',\n",
    "          'philosophy of language', 'philosophy of law', 'philosophy of mind',\n",
    "          'philosophy of science', 'economics', 'accounting', 'education',\n",
    "          'linguistics', 'law', 'psychology', 'sociology', 'electronics',\n",
    "          'software engineering', 'robotics',\n",
    "          'calculus', 'geometry', 'abstract algebra',\n",
    "          'Boolean algebra', 'commutative algebra', 'group theory', 'linear algebra',\n",
    "          'number theory', 'dynamical systems and differential equations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved = '/Users/harangju/Developer/data/wiki/graphs/dated/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics = ['earth science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wiki\n",
    "\n",
    "networks = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    networks[topic] = wiki.Net(path_graph=path_saved + topic + '.pickle',\n",
    "                               path_barcodes=path_saved + topic + '.barcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_null = '/Users/harangju/Developer/data/wiki/graphs/null-target/'\n",
    "num_nulls = 10\n",
    "null_targets = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    null_targets[topic] = [None for i in range(num_nulls)]\n",
    "    for i in range(num_nulls):\n",
    "        null_targets[topic][i] = wiki.Net(path_graph=path_null + topic + '-null-' + str(i) + '.pickle',\n",
    "                                          path_barcodes=path_null + topic + '-null-' + str(i) + '.barcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_null = '/Users/harangju/Developer/data/wiki/graphs/null-year/'\n",
    "num_nulls = 10\n",
    "null_years = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    null_years[topic] = [None for i in range(num_nulls)]\n",
    "    for i in range(num_nulls):\n",
    "        null_years[topic][i] = wiki.Net(path_graph=path_null + topic + '-null-' + str(i) + '.pickle',\n",
    "                                        path_barcodes=path_null + topic + '-null-' + str(i) + '.barcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_fig = '/Users/harangju/Box Sync/Research/my papers/wikipedia/results/'\n",
    "save_fig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "path_analysis = '/Users/harangju/Developer/data/wiki/analysis/'\n",
    "df = pickle.load(open(path_analysis+'stats.pickle', 'rb'))\n",
    "df_expand = pickle.load(open(path_analysis+'stats_expand.pickle', 'rb'))\n",
    "df.topic = df.topic.astype('object')\n",
    "df.measure = df.measure.astype('object')\n",
    "df_expand.topic = df_expand.topic.astype('object')\n",
    "df_expand.measure = df_expand.measure.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = df_expand\\\n",
    "    .groupby(['topic', 'measure'], as_index=False)\\\n",
    "    .mean()\\\n",
    "    .pivot(index='topic', columns='measure', values='value')\\\n",
    "    .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_mean['coreness-null-target'],\n",
    "                         y=df_mean['coreness'],\n",
    "                         mode='markers+text',\n",
    "                         name='coreness',\n",
    "                         text=df_mean['topic'],\n",
    "                         textposition='top left'))\n",
    "fig.add_trace(go.Scatter(x=[0,1], y=[0,1],\n",
    "                         mode='lines',\n",
    "                         line=dict(dash='dash'),\n",
    "                         name='1:1'))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  title='coreness',\n",
    "                  width=900, height=900,\n",
    "                  xaxis=dict(title='null',\n",
    "                             range=[0,1]),\n",
    "                  yaxis=dict(title='real',\n",
    "                             range=[0,1],\n",
    "                             scaleanchor='x',\n",
    "                             scaleratio=1))\n",
    "fig.show()\n",
    "# if save_fig:\n",
    "#     fig.write_image(f\"{path_fig}/{path_plot}/coreness.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_mean['modularity-null-target'],\n",
    "                         y=df_mean['modularity'],\n",
    "                         mode='markers+text',\n",
    "                         name='modularity',\n",
    "                         text=df_mean['topic'],\n",
    "                         textposition='bottom right'))\n",
    "fig.add_trace(go.Scatter(x=[0,1], y=[0,1],\n",
    "                         mode='lines',\n",
    "                         line=dict(dash='dash'),\n",
    "                         name='1:1'))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  title='modularity',\n",
    "                  width=900, height=900,\n",
    "                  xaxis=dict(title='null',\n",
    "                             range=[0,1]),\n",
    "                  yaxis=dict(title='real',\n",
    "                             range=[0,1],\n",
    "                             scaleanchor='x',\n",
    "                             scaleratio=1))\n",
    "fig.show()\n",
    "# if save_fig:\n",
    "#     fig.write_image(f\"{path_fig}/{path_plot}/modularity.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_big = os.path.join('/','Users','harangju','Box Sync','Research','my papers','wikipedia',\n",
    "#                         'results','0 graphs','gexf','big_graph.gexf')\n",
    "# big_net = wiki.Net(path_graph=path_big)\n",
    "# big_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki.Net.assign_core_periphery(big_net.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cavity statistics\n",
    "\n",
    "More dense connections\n",
    "In harder sciences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "# path_fig = '/Users/harangju/Box Sync/Research/my papers/wikipedia/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes = pd.concat([network.barcodes.assign(topic=topic)\\\n",
    "                                      .assign(type='real')\\\n",
    "                                      .assign(null=0)\n",
    "                      for topic, network in networks.items()] +\n",
    "                     [network.barcodes.assign(topic=topic)\\\n",
    "                                      .assign(type='targets')\\\n",
    "                                      .assign(null=i)\n",
    "                      for topic, nulls in null_targets.items()\n",
    "                          for i, network in enumerate(nulls)] +\n",
    "                     [network.barcodes.assign(topic=topic)\\\n",
    "                                      .assign(type='years')\\\n",
    "                                      .assign(null=i)\n",
    "                      for topic, nulls in null_years.items()\n",
    "                          for i, network in enumerate(nulls)],\n",
    "                     ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count = barcodes\\\n",
    "    .groupby(['type','topic','dim'], as_index=False)['null'].max()\n",
    "null_count.null = null_count.null + 1\n",
    "null_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_count = barcodes\\\n",
    "    .assign(count=1)\\\n",
    "    .groupby(['type','topic','dim'], as_index=False)['count'].sum()\\\n",
    "    .sort_values('type', axis=0, ascending=True)\n",
    "dim_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = pd\\\n",
    "    .merge(dim_count, null_count, how='left', left_on=['type','topic','dim'], right_on=['type','topic','dim'])\\\n",
    "    .sort_values(by=['type','topic','dim'])\\\n",
    "    .reset_index(drop=True)\\\n",
    "    .rename(columns={'count': 'dim_count', 'null': 'null_count'})\n",
    "dims['dim_count_norm'] = dims['dim_count'] / dims.null_count\n",
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(dims[dims.type=='real'], x='dim', y='dim_count_norm')\n",
    "for topic in pd.unique(dims['topic']):\n",
    "    data = dims[(dims['type']=='real') & (dims['topic']==topic)].sort_values(by='dim')\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data['dim'], y=data['dim_count_norm'], name=topic,\n",
    "        mode='markers+lines', visible='legendonly'\n",
    "    ))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  title_text='Dimensionality',\n",
    "                  yaxis={'range': [0,10000]})\n",
    "fig.update_traces(marker={'size': 3}, line={'width': 1})\n",
    "fig.show()\n",
    "# fig.write_image(os.path.join(path_fig, path_plot, 'dimensionality_real.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "dim_stats = pd.DataFrame(dims\\\n",
    "    .groupby(['type','topic'])['dim_count_norm'].idxmax())\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={'dim_count_norm': 'dim_mode_idx'})\n",
    "dim_stats['mode'] = dims.iloc[dim_stats['dim_mode_idx']]['dim'].values\n",
    "dim_stats = dim_stats.drop('dim_mode_idx', axis=1)\n",
    "dim_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = dims\\\n",
    "    .assign(dimXcount=dims['dim'] * dims['dim_count_norm'])\\\n",
    "    .groupby('topic', as_index=False)['dim_count_norm','dimXcount'].sum()\\\n",
    "    .rename(columns={'dim_count_norm': 'dim_count_norm_sum'})\n",
    "dim_stats['mean'] = avg['dimXcount'] / avg['dim_count_norm_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 111\n",
    "dim_stats[dim_stats['type']=='real']\\\n",
    "    .sort_values(['mean'])\\\n",
    "    .reset_index()\\\n",
    "    .drop(['type','index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we say that the dimensionality of cavities reveals the complexity of the information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_net = wiki.Net(path_graph=os.path.join(path_saved, 'big_network.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix(big_net.graph)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_net.graph['Commercial law']['Unfair competition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_net.graph['Unfair competition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(big_net.graph.nodes).index('Commercial law'), list(big_net.graph.nodes).index('Unfair competition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0,1], a[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communicability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communicability(A):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controllability\n",
    "\n",
    "Is there a spectrum of controllability in nodes & topics (as summarized over nodes) from \"pure\" to \"applied\" fields?\n",
    "\n",
    "Make sure to check outdegree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation: `a[i,j]` means that `i` points to `j` and that page `i` is linked to from page `j` in Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gramians(A, M):\n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A: scipy.sparse.csc_matrix or csr_matrix\n",
    "        turns csr_matrix into csc_matrix\n",
    "        A[i,j] should have j->i\n",
    "    M: int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    CG, OG: scipy.sparse.csc_matrix\n",
    "        controllability & observability Gramians\n",
    "    '''\n",
    "    if isinstance(A, sp.sparse.csr_matrix):\n",
    "        A = A.transpose()\n",
    "    val, vec = sp.sparse.linalg.eigs(a.transpose())\n",
    "    # pre-calculate A^m and (A^T)^m\n",
    "    Anorm = A / (1 + val[0])\n",
    "    AnormT = Anorm.transpose().tocsc()\n",
    "    Am = [sp.sparse.identity(A.shape[0], dtype=np.float64, format='csc'), Anorm]\n",
    "    ATm = [sp.sparse.identity(A.shape[0], dtype=np.float64, format='csc'), AnormT]\n",
    "    for m in range(2,M+1):\n",
    "        Am += [Am[-1] * Anorm]\n",
    "        ATm += [ATm[-1] * AnormT]\n",
    "    # calculate controllability & observability Gramians\n",
    "    CG = Am[0] * ATm[0]\n",
    "    OG = ATm[0] * Am[0]\n",
    "    for m in range(1,M+1):\n",
    "        print('G ' + str(m))\n",
    "        CG += Am[m] * ATm[m]\n",
    "        OG += ATm[m] * Am[m]\n",
    "    return CG, OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG, OG = gramians(A, 1)\n",
    "len(CG.diagonal()[np.nonzero(CG.diagonal()-1)[0]]), np.nonzero(CG.diagonal()-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 3\n",
    "nodes = list(big_net.graph.nodes)\n",
    "grams = pd.DataFrame({'node': nodes})\n",
    "for m in range(1,M+1):\n",
    "    print(f\"m={m}\")\n",
    "    CG, OG = gramians(A, m)\n",
    "    grams[f\"CG_{m}\"] = CG.diagonal()\n",
    "    grams[f\"OG_{m}\"] = OG.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del CG, OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams = grams.set_index('node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path_save = os.path.join('/','Users','harangju','Developer','data','wiki','analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(grams, open(os.path.join(path_save, 'grams.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams = pickle.load(open(os.path.join(path_save, 'grams.pickle'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_rows = 100\n",
    "num_rows = 20\n",
    "pd.DataFrame(np.concatenate((\n",
    "    [grams.sort_values('OG_1', ascending=False).iloc[0:num_rows].index.values],\n",
    "    [grams.sort_values('OG_2', ascending=False).iloc[0:num_rows].index.values],\n",
    "    [grams.sort_values('OG_3', ascending=False).iloc[0:num_rows].index.values]),\n",
    "    axis=0).transpose(),\n",
    "            columns=['OG_1','OG_2','OG_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pd.options.display.max_rows = 100\n",
    "num_rows = 20\n",
    "pd.DataFrame(np.concatenate((\n",
    "    [grams.sort_values('CG_1', ascending=False).iloc[0:num_rows].index.values],\n",
    "    [grams.sort_values('CG_2', ascending=False).iloc[0:num_rows].index.values],\n",
    "    [grams.sort_values('CG_3', ascending=False).iloc[0:num_rows].index.values]),\n",
    "    axis=0).transpose(),\n",
    "            columns=['CG_1','CG_2','CG_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams_topics = pd.DataFrame()\n",
    "for topic in topics:\n",
    "    vals = {key: 0 for key in grams.columns.values}\n",
    "    for key in vals:\n",
    "        vals[key] = np.mean([grams.loc[node][key] for node in networks[topic].graph.nodes])\n",
    "    grams_topics = pd.concat([grams_topics,\n",
    "                              pd.DataFrame([[topic] + [v for k,v in vals.items()]], \n",
    "                                           columns=['topic']+list(vals.keys()))\n",
    "                             ])\n",
    "grams_topics = grams_topics.set_index('topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams_topics.sort_values('OG_1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
