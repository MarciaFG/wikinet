{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WikiEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wiki.dump import WikiDump\n",
    "import wiki\n",
    "\n",
    "path_base = '/Users/harangju/Developer/data/wiki/'\n",
    "name_xml = 'enwiki-20190801-pages-articles-multistream.xml.bz2'\n",
    "name_index = 'enwiki-20190801-pages-articles-multistream-index.txt.bz2'\n",
    "path_xml = path_base + name_xml\n",
    "path_index = path_base + name_index\n",
    "dump = wiki.Dump(path_xml, path_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the wiki dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump: Loading index...\n",
      "Dump: Loaded.\n",
      "CPU times: user 1min 16s, sys: 2.56 s, total: 1min 19s\n",
      "Wall time: 1min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Classical physics', 'Mechanics', 'Optics', 'Electricity', 'Magnetism']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time dump.load_page('Portal:Physics/Topics')\n",
    "dump.links[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['University of pennsylvania',\n",
       " 'Pennsylvania state university',\n",
       " 'University of cambridge']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump.load_page('Danielle Bassett')\n",
    "dump.links[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In classical physics and general chemistry, matter is any substance that has mass and takes up space by having volume. All everyday objects that can be touched are ultimately composed of atoms, which '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump.load_page('Matter', filter_top=True).strip_code()[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get index of physics articles\n",
    "\n",
    "* [all indices on Wikipedia](https://en.wikipedia.org/wiki/Portal:Contents/Indices)\n",
    "* topics not searched\n",
    "* international trade (\"topics\"), theory of constraints (small)\n",
    "* too big: mathematics, neuroscience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "links = {}\n",
    "# natural & physical sciences\n",
    "topics = ['anatomy', 'biochemistry', 'cognitive science', 'evolutionary biology',\n",
    "          'genetics', 'immunology', 'molecular biology']\n",
    "topics += ['chemistry', 'biophysics', 'energy', 'optics', \n",
    "           'earth science', 'geology', 'meteorology']\n",
    "# philosophy\n",
    "# topics += []\n",
    "topics += ['philosophy of language', 'philosophy of law', \n",
    "           'philosophy of mind', 'philosophy of science']\n",
    "# social sciences\n",
    "topics += ['economics', 'accounting', 'education', 'linguistics', 'law', 'psychology', 'sociology']\n",
    "# technology & applied sciences\n",
    "topics += ['electronics', 'software engineering', 'robotics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic \"anatomy\" has 2331 articles.\n",
      "Topic \"biochemistry\" has 1216 articles.\n",
      "Topic \"cognitive science\" has 127 articles.\n",
      "Topic \"evolutionary biology\" has 287 articles.\n",
      "Topic \"genetics\" has 1441 articles.\n",
      "Topic \"immunology\" has 572 articles.\n",
      "Topic \"molecular biology\" has 507 articles.\n",
      "Topic \"chemistry\" has 1088 articles.\n",
      "Topic \"biophysics\" has 773 articles.\n",
      "Topic \"energy\" has 158 articles.\n",
      "Topic \"optics\" has 386 articles.\n",
      "Topic \"earth science\" has 135 articles.\n",
      "Topic \"geology\" has 116 articles.\n",
      "Topic \"meteorology\" has 761 articles.\n",
      "Topic \"philosophy of language\" has 275 articles.\n",
      "Topic \"philosophy of law\" has 208 articles.\n",
      "Topic \"philosophy of mind\" has 109 articles.\n",
      "Topic \"philosophy of science\" has 448 articles.\n",
      "Topic \"economics\" has 562 articles.\n",
      "Topic \"accounting\" has 154 articles.\n",
      "Topic \"education\" has 872 articles.\n",
      "Topic \"linguistics\" has 420 articles.\n",
      "Topic \"law\" has 3657 articles.\n",
      "Topic \"psychology\" has 1801 articles.\n",
      "Topic \"sociology\" has 772 articles.\n",
      "Topic \"electronics\" has 1274 articles.\n",
      "Topic \"software engineering\" has 251 articles.\n",
      "Topic \"robotics\" has 1432 articles.\n"
     ]
    }
   ],
   "source": [
    "for topic in topics:\n",
    "    dump.load_page('Index of %s articles' % topic)\n",
    "    links[topic] = [str(l) for l in dump.article_links]\n",
    "    print('Topic \"' + topic + '\" has ' + str(len(links[topic])) + ' articles.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic \"physics\" has 15215 articles.\n"
     ]
    }
   ],
   "source": [
    "links['physics'] = []\n",
    "for letter in ['!$@', '0â€“9'] + list(string.ascii_uppercase):\n",
    "    dump.load_page('Index of physics articles (%s)' % letter)\n",
    "    links['physics'].extend([str(l) for l in dump.article_links])\n",
    "print('Topic \"' + 'physics' + '\" has ' + str(len(links['physics'])) + ' articles.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build graphs of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph topic: anatomy\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 7760\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 788\n",
      "Depth: 2\n",
      "Graph topic: biochemistry\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 4390\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 437\n",
      "Depth: 2\n",
      "Graph topic: cognitive science\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 480\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 49\n",
      "Depth: 2\n",
      "Graph topic: evolutionary biology\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 116\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 960\n",
      "Depth: 2\n",
      "Graph topic: genetics\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 4260\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 368\n",
      "Depth: 2\n",
      "Graph topic: immunology\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 142\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 990\n",
      "Depth: 2\n",
      "Graph topic: molecular biology\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 160\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 135\n",
      "Depth: 2\n",
      "Graph topic: chemistry\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 4120\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 435\n",
      "Depth: 2\n",
      "Graph topic: biophysics\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 119\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 610\n",
      "Depth: 2\n",
      "Graph topic: energy\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 370\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 21\n",
      "Depth: 2\n",
      "Graph topic: optics\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 128\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 108\n",
      "Depth: 2\n",
      "Graph topic: earth science\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 530\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 48\n",
      "Depth: 2\n",
      "Graph topic: geology\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 310\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 22\n",
      "Depth: 2\n",
      "Graph topic: meteorology\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 269\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 233\n",
      "Depth: 2\n",
      "Graph topic: philosophy of language\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 850\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 35\n",
      "Depth: 2\n",
      "Graph topic: philosophy of law\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 390\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 18\n",
      "Depth: 2\n",
      "Graph topic: philosophy of mind\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 340\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 22\n",
      "Depth: 2\n",
      "Graph topic: philosophy of science\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 113\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 600\n",
      "Depth: 2\n",
      "Graph topic: economics\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 213\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 194\n",
      "Depth: 2\n",
      "Graph topic: accounting\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 450\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 30\n",
      "Depth: 2\n",
      "Graph topic: education\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 196\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 108\n",
      "Depth: 2\n",
      "Graph topic: linguistics\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 165\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 167\n",
      "Depth: 2\n",
      "Graph topic: law\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 1088\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 8610\n",
      "Depth: 2\n",
      "Graph topic: psychology\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 4990\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 417\n",
      "Depth: 2\n",
      "Graph topic: sociology\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 244\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 208\n",
      "Depth: 2\n",
      "Graph topic: electronics\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 4100\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 315\n",
      "Depth: 2\n",
      "Graph topic: software engineering\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 101\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 740\n",
      "Depth: 2\n",
      "Graph topic: robotics\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 2920\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 124\n",
      "Depth: 2\n",
      "Graph topic: physics\n",
      "Depth: 0\n",
      "Crawler: len(queue) = 45160\n",
      "Depth: 1\n",
      "Crawler: len(queue) = 3464\n",
      "Depth: 2\n",
      "Crawler: len(queue) = 3463"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "graphs = {}\n",
    "page_noload = {}\n",
    "depth = 2\n",
    "for topic in links.keys():\n",
    "    print('Graph topic: ' + topic)\n",
    "    graphs[topic] = nx.DiGraph()\n",
    "    page_noload[topic] = wiki.Crawler.bfs(graphs[topic], dump, links[topic],\n",
    "                                          depth_goal = depth, nodes = links[topic])\n",
    "    path_save = path_base + 'graphs/' + topic + '_d' + str(depth) + '.gexf'\n",
    "    nx.write_gexf(graphs[topic], path_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
