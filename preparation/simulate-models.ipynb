{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext cython\n",
    "%reload_ext line_profiler\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..', 'module'))\n",
    "import wiki\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import cufflinks as cf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['anatomy', 'biochemistry', 'cognitive science', 'evolutionary biology',\n",
    "          'genetics', 'immunology', 'molecular biology', 'chemistry', 'biophysics',\n",
    "          'energy', 'optics', 'earth science', 'geology', 'meteorology',\n",
    "          'philosophy of language', 'philosophy of law', 'philosophy of mind',\n",
    "          'philosophy of science', 'economics', 'accounting', 'education',\n",
    "          'linguistics', 'law', 'psychology', 'sociology', 'electronics',\n",
    "          'software engineering', 'robotics',\n",
    "          'calculus', 'geometry', 'abstract algebra',\n",
    "          'Boolean algebra', 'commutative algebra', 'group theory', 'linear algebra',\n",
    "          'number theory', 'dynamical systems and differential equations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved = '/Users/harangju/Developer/data/wiki/graphs/dated/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "networks = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    networks[topic] = wiki.Net()\n",
    "    networks[topic].load_graph(path_saved + topic + '.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "dct = pickle.load(open('/Users/harangju/Developer/data/wiki/models/' + 'dict.model','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%cython -f\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from cython cimport floating,boundscheck,wraparound\n",
    "from cython.parallel import prange\n",
    "\n",
    "from libc.math cimport fabs\n",
    "\n",
    "np.import_array()\n",
    "\n",
    "@boundscheck(False)  # Deactivate bounds checking\n",
    "@wraparound(False)\n",
    "def cython_manhattan(floating[::1] X_data, int[:] X_indices, int[:] X_indptr,\n",
    "                     floating[::1] Y_data, int[:] Y_indices, int[:] Y_indptr,\n",
    "                     double[:, ::1] D):\n",
    "    \"\"\"Pairwise L1 distances for CSR matrices.\n",
    "    Usage:\n",
    "    >>> D = np.zeros(X.shape[0], Y.shape[0])\n",
    "    >>> cython_manhattan(X.data, X.indices, X.indptr,\n",
    "    ...                  Y.data, Y.indices, Y.indptr,\n",
    "    ...                  D)\n",
    "    \"\"\"\n",
    "    cdef np.npy_intp px, py, i, j, ix, iy\n",
    "    cdef double d = 0.0\n",
    "    \n",
    "    cdef int m = D.shape[0]\n",
    "    cdef int n = D.shape[1]\n",
    "    \n",
    "    with nogil:                          \n",
    "        for px in prange(m):\n",
    "            for py in range(n):\n",
    "                i = X_indptr[px]\n",
    "                j = Y_indptr[py]\n",
    "                d = 0.0\n",
    "                while i < X_indptr[px+1] and j < Y_indptr[py+1]:\n",
    "                    if i < X_indptr[px+1]: ix = X_indices[i]\n",
    "                    if j < Y_indptr[py+1]: iy = Y_indices[j]\n",
    "                    \n",
    "                    if ix==iy:\n",
    "                        d = d+fabs(X_data[i]-Y_data[j])\n",
    "                        i = i+1\n",
    "                        j = j+1\n",
    "                    \n",
    "                    elif ix<iy:\n",
    "                        d = d+fabs(X_data[i])\n",
    "                        i = i+1\n",
    "                    else:\n",
    "                        d = d+fabs(Y_data[j])\n",
    "                        j = j+1\n",
    "                \n",
    "                if i== X_indptr[px+1]:\n",
    "                    while j < Y_indptr[py+1]:\n",
    "                        iy = Y_indices[j]\n",
    "                        d = d+fabs(Y_data[j])\n",
    "                        j = j+1                                            \n",
    "                else:\n",
    "                    while i < X_indptr[px+1]:\n",
    "                        ix = X_indices[i]\n",
    "                        d = d+fabs(X_data[i])\n",
    "                        i = i+1\n",
    "                        \n",
    "                D[px,py] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as skp\n",
    "import sklearn.metrics.pairwise as smp\n",
    "\n",
    "def year_diffs(graph):\n",
    "    return [graph.nodes[node]['year'] - graph.nodes[neighbor]['year']\n",
    "            for node in graph.nodes\n",
    "            for neighbor in list(graph.successors(node))]\n",
    "\n",
    "def neighbor_similarity(graph, tfidf):\n",
    "    nodes = list(graph.nodes)\n",
    "    return [smp.cosine_similarity(tfidf[:,nodes.index(node)].transpose(),\n",
    "                                  tfidf[:,nodes.index(neighbor)].transpose())[0,0]\n",
    "            for node in nodes\n",
    "            for neighbor in list(graph.successors(node))]\n",
    "\n",
    "def sparse_manhattan(X,Y=None):\n",
    "    X, Y = smp.check_pairwise_arrays(X, Y)\n",
    "    X = sp.sparse.csr_matrix(X, copy=False)\n",
    "    Y = sp.sparse.csr_matrix(Y, copy=False)\n",
    "    res = np.empty(shape=(X.shape[0],Y.shape[0]))\n",
    "    cython_manhattan(X.data,X.indices,X.indptr,\n",
    "                     Y.data,Y.indices,Y.indptr,\n",
    "                             res)\n",
    "    return res\n",
    "\n",
    "def word_diffs(graph, tfidf):\n",
    "    dists = sparse_manhattan(X=skp.binarize(tfidf).transpose())\n",
    "    nodes = list(graph.nodes)\n",
    "    return [dists[nodes.index(node), nodes.index(neighbor)]\n",
    "            for node in nodes\n",
    "            for neighbor in list(graph.successors(node))]\n",
    "\n",
    "def sum_abs_weight_differences(graph, tfidf):\n",
    "    nodes = list(graph.nodes)\n",
    "    diff = []\n",
    "    for node in nodes:\n",
    "        for neighbor in graph.successors(node):\n",
    "            v1 = tfidf[:,nodes.index(node)]\n",
    "            v2 = tfidf[:,nodes.index(neighbor)]\n",
    "            idx = np.concatenate([v1.indices, v2.indices])\n",
    "            diff.append( np.sum(np.absolute(v1[idx]-v2[idx])) )\n",
    "    return diff\n",
    "\n",
    "def sum_weight_differences(graph, tfidf):\n",
    "    nodes = list(graph.nodes)\n",
    "    diff = []\n",
    "    for node in nodes:\n",
    "        for neighbor in graph.successors(node):\n",
    "            v1 = tfidf[:,nodes.index(node)]\n",
    "            v2 = tfidf[:,nodes.index(neighbor)]\n",
    "            idx = np.concatenate([v1.indices, v2.indices])\n",
    "            diff.append( np.sum(v1[idx]-v2[idx]) )\n",
    "    return diff\n",
    "\n",
    "def bin_distribution(data, steps=30, scale='log'):\n",
    "    if scale=='log':\n",
    "        bins = np.logspace(np.log10(np.min(data)), np.log10(np.max(data)), steps)\n",
    "    elif scale=='linear':\n",
    "        bins = np.linspace(np.min(data), np.max(data), num=steps)\n",
    "    hist, edges = np.histogram(data, bins=bins)\n",
    "    return hist, edges, bins\n",
    "\n",
    "def plot_distribution(data):\n",
    "    hist, edges, bins = bin_distribution(data)\n",
    "#     hist_norm = hist/(bins[1:] - bins[:-1])\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=bins[:-1],\n",
    "                             y=hist/len(data),\n",
    "                             mode='markers'))\n",
    "    fig.update_layout(template='plotly_white',\n",
    "                      xaxis={'type': 'log',\n",
    "                             'title': 'x'},\n",
    "                      yaxis={'type': 'log',\n",
    "                             'title': 'P(x)'})\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "path_fig = '/Users/harangju/Box Sync/Research/my papers/wikipedia/results/'\n",
    "save_fig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "topic = 'anatomy'\n",
    "path_plot = '3 model ex prior'\n",
    "\n",
    "if not os.path.exists(os.path.join(path_fig, path_plot, topic)):\n",
    "    os.mkdir(os.path.join(path_fig, path_plot, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_distribution(networks[topic].graph.graph['tfidf'].data)\n",
    "if save_fig:\n",
    "    fig.write_image(os.path.join(path_fig, path_plot, topic, 'tf_idf_distribution.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yd = year_diffs(networks[topic].graph)\n",
    "wd = word_diffs(networks[topic].graph, networks[topic].graph.graph['tfidf'])\n",
    "a, b, fit_r, p, stderr = sp.stats.linregress(np.abs(yd), wd)\n",
    "fig = go.Figure()\n",
    "x = np.linspace(0, max(yd), 100)\n",
    "fig.add_trace(go.Scatter(x=np.abs(yd), y=wd,\n",
    "                         mode='markers',\n",
    "                         marker={'size': 3},\n",
    "                         name='edges'))\n",
    "fig.add_trace(go.Scatter(x=x, y=np.multiply(a, x) + b,\n",
    "                         name=f\"y = {a:.1f} x + {b:.1f}\"))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  title=f\"{topic} (r = {fit_r:.2f}, p = {p:.1e})\",\n",
    "                  xaxis={'title': 'Δyear'},\n",
    "                  yaxis={'title': 'manhattan distance'})\n",
    "fig.show()\n",
    "if save_fig:\n",
    "    fig.write_image(os.path.join(path_fig, path_plot, topic, 'manhattan.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_weight_diffs = sum_weight_differences(networks[topic].graph,\n",
    "                                          networks[topic].graph.graph['tfidf'])\n",
    "a, b, fit_r_sum_weight, p, stderr = sp.stats.linregress(np.abs(yd), sum_weight_diffs)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.abs(yd),\n",
    "                         y=sum_weight_diffs,\n",
    "                         mode='markers',\n",
    "                         marker={'size': 3},\n",
    "                         name='edges'))\n",
    "x = np.linspace(0, max(yd), 100)\n",
    "fig.add_trace(go.Scatter(x=x, y=np.multiply(a, x) + b,\n",
    "                         name=f\"y = {a:.1e} x + {b:.1f}\\n\"))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  title=f\"{topic} (r = {fit_r_sum_weight:.2f}; p = {p:.1e})\",\n",
    "                  xaxis={'title': 'Δyear'},\n",
    "                  yaxis={'title': 'Σ Δw_i'})\n",
    "fig.show()\n",
    "if save_fig:\n",
    "    fig.write_image(os.path.join(path_fig, path_plot, topic, 'sum_diff_weights.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of word weights are not changing significantly across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "a, b, fit_r_sum_weight, p, stderr = sp.stats.linregress(np.abs(yd), sum_weight_diffs)\n",
    "mu_swd, std_swd = np.mean(sum_weight_diffs), np.std(sum_weight_diffs)\n",
    "fig = ff.create_distplot([sum_weight_diffs], ['edges'], bin_size=1)\n",
    "x = np.linspace(min(sum_weight_diffs), max(sum_weight_diffs), 100)\n",
    "fig.add_trace(go.Scatter(x=x, y=sp.stats.norm.pdf(x, mu_swd, std_swd),\n",
    "                         name='normal fit'))\n",
    "fig.update_layout(template='plotly_white', title=topic,\n",
    "                  xaxis={'title': 'Σ Δw_i'})\n",
    "fig.show()\n",
    "if save_fig:\n",
    "    fig.write_image(os.path.join(path_fig, path_plot, topic, 'sum_diff_weights_dstr.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_abs_weight_diffs = sum_abs_weight_differences(networks[topic].graph,\n",
    "                                                  networks[topic].graph.graph['tfidf'])\n",
    "a, b, fit_r_sum_abs_weight, p, stderr = sp.stats.linregress(np.abs(yd), sum_abs_weight_diffs)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.abs(yd),\n",
    "                         y=sum_abs_weight_diffs,\n",
    "                         mode='markers',\n",
    "                         marker={'size': 3},\n",
    "                         name='edges'))\n",
    "x = np.linspace(0, max(yd), 100)\n",
    "fig.add_trace(go.Scatter(x=x, y=np.multiply(a, x) + b,\n",
    "                         name=f\"y = {a:.1e} x + {b:.1f}\\n\"))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  title=f\"{topic} (r = {fit_r_sum_abs_weight:.2f}; p = {p:.1e})\",\n",
    "                  xaxis={'title': 'Δyear'},\n",
    "                  yaxis={'title': 'Σ |Δw_i|'})\n",
    "fig.show()\n",
    "if save_fig:\n",
    "    fig.write_image(os.path.join(path_fig, path_plot, topic, 'sum_abs_diff_weights.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = neighbor_similarity(networks[topic].graph, networks[topic].graph.graph['tfidf'])\n",
    "mu_n, std_n = sp.stats.norm.fit(neighbors)\n",
    "mu_n, std_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "fig = ff.create_distplot([neighbors], ['edges'], bin_size=.05)\n",
    "x = np.linspace(min(neighbors), max(neighbors), 100)\n",
    "fig.add_trace(go.Scatter(x=x, y=sp.stats.norm.pdf(x, mu_n, std_n),\n",
    "                         name='normal fit'))\n",
    "fig.update_layout(template='plotly_white', title=topic,\n",
    "                  xaxis={'title': 'cosine similarity'})\n",
    "fig.show()\n",
    "if save_fig:\n",
    "    fig.write_image(os.path.join(path_fig, path_plot, topic, 'cosine_distribution.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "stoplist=set('for a of the and to in'.split())\n",
    "nodes = []\n",
    "words = []\n",
    "graph = networks[topic].graph\n",
    "tfidf = networks[topic].graph.graph['tfidf']\n",
    "for i in range(tfidf.shape[1]):\n",
    "    node = list(graph.nodes)[i]\n",
    "    if tfidf[:,i].data.size == 0:\n",
    "#         print(node, tfidf[:,i].data)\n",
    "        continue\n",
    "    top_words, idx = wiki.Model.find_top_words(tfidf[:,i], dct, top_n=5)\n",
    "    nodes += [node]\n",
    "    words += [top_words]\n",
    "pd.DataFrame(data={'Node': nodes, 'Top words': words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "k=4\n",
    "x = np.sum(np.abs(np.random.randint(0,n,(k,100000))-np.random.randint(0,n,(k,100000))), axis=0)\n",
    "# np.mean(x), k*2*np.sum(np.arange(1,n)*np.flip(np.arange(1,n))) * ((1/n)**2)\n",
    "np.mean(x), k * np.sum( ((1/n)**2) * np.sum(np.abs(np.array([np.arange(n)]).transpose()-np.arange(n)),\n",
    "                                            axis=0) )\n",
    "# k * Σ_i P(x_i) * Σ_j |x_i-x_j|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = networks[topic].graph.graph['tfidf']\n",
    "rvs = lambda n: tfidf.data[np.random.choice(tfidf.data.size, size=n)]\n",
    "emp = np.mean(np.sum(np.abs(rvs((1,100000))-rvs((1,100000))), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,e,_ = bin_distribution(tfidf.data, 100, 'linear')\n",
    "p_x = h/len(tfidf.data)\n",
    "x = np.array([np.average([e[:-1],e[1:]], axis=0)])\n",
    "the = np.sum(p_x * np.sum(np.abs(p_x*x.transpose() - x), axis=0))\n",
    "emp, the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import dill\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "stats = pd.DataFrame()\n",
    "for topic, network in networks.items():\n",
    "    models[topic] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_n_nodes = 10\n",
    "start_condition = lambda m: [n for n in m.graph_parent.nodes\n",
    "                             if m.graph_parent.nodes[n]['year'] <=\\\n",
    "                                 sorted(list(nx.get_node_attributes(m.graph_parent, 'year')\\\n",
    "                                               .values()))[first_n_nodes]]\n",
    "end_condition = lambda m: (len(m.graph.nodes) >= len(m.graph_parent.nodes)) or \\\n",
    "                          (m.year > 2500)\n",
    "n_seeds = 2\n",
    "n_models = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.join('/', 'Users', 'harangju', 'Developer', 'data', 'wiki', 'simulations')\n",
    "save_models = True\n",
    "base_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "_networks = copy.deepcopy(networks)\n",
    "_networks.pop('anatomy', None)\n",
    "_networks.pop('biochemistry', None)\n",
    "_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for topic, network in _networks.items():\n",
    "    print(topic)\n",
    "    print('\\tAnalyzing priors...')\n",
    "    tfidf = network.graph.graph['tfidf']\n",
    "    yd = year_diffs(network.graph)\n",
    "    md = word_diffs(network.graph, tfidf)\n",
    "    a_md, b_md, r_md, p_md, stderr = sp.stats.linregress(np.abs(yd), md)\n",
    "    swd = sum_abs_weight_differences(network.graph, tfidf)\n",
    "    a_swd, b_swd, r_swd, p_swd, stderr = sp.stats.linregress(np.abs(yd), swd)\n",
    "    rvs = lambda n: tfidf.data[np.random.choice(tfidf.data.size, size=n)]\n",
    "    mu_sawd = np.mean(np.sum(np.abs(rvs((1,100000))-rvs((1,100000))), axis=0))\n",
    "    nb = neighbor_similarity(network.graph, tfidf)\n",
    "    mu_nb, std_nb = sp.stats.norm.fit(nb)\n",
    "    p_point, p_insert, p_delete = a_swd/mu_sawd, a_md/2, a_md/2\n",
    "    new_stats = pd.DataFrame([[p_point,p_insert,p_delete,\n",
    "                               a_md,b_md,r_md,p_md,\n",
    "                               a_swd,b_swd,r_swd,p_swd,\n",
    "                               mu_sawd,mu_nb,std_nb]],\n",
    "                             columns=['p_pt', 'p_in', 'p_de',\n",
    "                                      'a (man)', 'b (man)', 'r (man)', 'p (man)',\n",
    "                                      'a (swd)', 'b (swd)', 'r (swd)', 'p (swd)',\n",
    "                                      'mu (sawd)', 'mu (nei)', 'std (nei)'\n",
    "                                     ])\n",
    "    display(HTML(new_stats.to_html()))\n",
    "    stats = pd.concat([stats, new_stats], ignore_index=True)\n",
    "    for i in range(n_models):\n",
    "        print(f\"\\tRunning model {i}...\")\n",
    "        model = wiki.Model(graph_parent=network.graph,\n",
    "                           vectors_parent=tfidf,\n",
    "                           year_start=sorted(list(nx.get_node_attributes(network.graph, 'year')\\\n",
    "                                                    .values()))[first_n_nodes],\n",
    "                           start_nodes=start_condition,\n",
    "                           n_seeds=n_seeds,\n",
    "                           dct=dct,\n",
    "                           point=(1, p_point),\n",
    "                           insert=(1, p_insert, list(set(tfidf.indices))),\n",
    "                           delete=(1, p_delete),\n",
    "                           rvs=rvs,\n",
    "                           create=lambda n: np.random.normal(loc=mu_nb, scale=std_nb, size=n))\n",
    "        models[topic].append(model)\n",
    "        model.evolve(until=end_condition)\n",
    "    if save_models:\n",
    "        now = datetime.datetime.now().strftime('%Y%m%d_%H%M')\n",
    "        dill.dump(models, open(os.path.join(base_dir, f\"models_{now}.pickle\"), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir = os.path.join('Users', 'harangju', 'Developer', 'data', 'wiki', 'simulations')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = lambda a,b: smp.cosine_similarity(a.transpose(), b.transpose())[0,0]\n",
    "nodes = list(model.graph.nodes)\n",
    "model.record['Similarity (parent)'] = [sim(model.record.iloc[i]['Seed vectors'], \n",
    "                                           model.vectors[:,nodes.index(\n",
    "                                               model.record.iloc[i]['Parent'])])\n",
    "                                       for i in range(len(model.record.index))]\n",
    "model.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Interesting thought\n",
    "If it weren't for the Middle Ages, we would have an amount of knowledge in the 16th Century that is similar to what we have now. But if we run the model after the Dark Ages, the model is accurate (?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s = lambda a,b: smp.cosine_similarity(a.transpose(), b.transpose())[0,0]\n",
    "nodes = list(model.graph.nodes)\n",
    "model.record['Similarity to parent'] = [s(model.record.iloc[i]['Seed vectors'],\n",
    "                                          model.vectors[:,nodes.index(model.record.iloc[i]['Parent'])])\n",
    "                                        for i in range(len(model.record.index))]\n",
    "model.record['Parent seed'] = model.record['Parent'] + ' ' + model.record['Seed number'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "ax = sns.lineplot(x='Year', y='Similarity to parent', hue='Parent seed', legend=False,\n",
    "                  data=model.record)\n",
    "plt.ylim([0,1.1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "from ipywidgets import interact, widgets, Layout\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Interactive plots\n",
    "[FigureWidgets](https://plot.ly/python/v3/figurewidget-app/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = cf.datagen.lines(5,1000).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def update(change):\n",
    "    with fig.batch_update():\n",
    "        fig.data[0].x = df.index[df.index > change.new]\n",
    "        fig.data[0].y = df[df.columns[0]][df.index > change.new]\n",
    "min_idx = min(df.index)\n",
    "max_idx = max(df.index)\n",
    "\n",
    "slider = widgets.IntSlider(value=0, min=min_idx, max=max_idx,\n",
    "                           step=1, description='Year', continuous_update=True,\n",
    "                           layout=Layout(width='auto'))\n",
    "slider.observe(update, names='value')\n",
    "display(slider)\n",
    "\n",
    "fig = go.FigureWidget()\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df[df.columns[0]], name=df.columns[0], mode='lines'))\n",
    "fig.update_layout(title='Title', xaxis_title='Index', yaxis_title='Y', template='plotly_white')\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree distribution\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "There are too many connections. Similarity to the parent isn't actually changing that much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=[d for _,d in graph.degree], nbinsx=30, name='empirical'))\n",
    "fig.add_trace(go.Histogram(x=[d for _,d in model.graph.degree], nbinsx=30, name='model'))\n",
    "fig.update_layout(title='Degree distribution', template='plotly_white',\n",
    "                  xaxis_title='degree', yaxis_title='number of edges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = pd.DataFrame([model.graph.nodes[node]['year'] for node in model.graph.nodes],\n",
    "                     columns=['Year'])\\\n",
    "          .sort_values(by='Year')\\\n",
    "          .reset_index(drop=True)\n",
    "years['count'] = 1\n",
    "years['Year (cumsum)'] = years['count'].cumsum()\n",
    "years = years.drop(columns='count')\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(model.graph.nodes)\n",
    "layout = nx.kamada_kawai_layout(model.graph, dim=2)\n",
    "# layout = nx.spring_layout(model.graph, dim=3)\n",
    "layout = np.vstack([layout[node] for node in nodes])\n",
    "Xn = [layout[k][0] for k in range(len(nodes))]\n",
    "Yn = [layout[k][1] for k in range(len(nodes))]\n",
    "# Zn = [layout[k][2] for k in range(len(nodes))]\n",
    "Xe = []\n",
    "Ye = []\n",
    "# Ze = []\n",
    "for e in model.graph.edges:\n",
    "    Xe += [layout[nodes.index(e[0])][0], layout[nodes.index(e[1])][0], None]\n",
    "    Ye += [layout[nodes.index(e[0])][1], layout[nodes.index(e[1])][1], None]\n",
    "#     Ze += [layout[nodes.index(e[0])][2], layout[nodes.index(e[1])][2], None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_layout(graph, nodes):\n",
    "    subgraph = model.graph.subgraph(nodes)\n",
    "    layout = nx.kamada_kawai_layout(graph, dim=2)\n",
    "    Xn = [layout[n][0] for n in subgraph.nodes]\n",
    "    Yn = [layout[n][1] for n in subgraph.nodes]\n",
    "    Xe = []\n",
    "    Ye = []\n",
    "    for e in subgraph.edges:\n",
    "        Xe += [layout[e[0]][0], layout[e[1]][0], None]\n",
    "        Ye += [layout[e[0]][1], layout[e[1]][1], None]\n",
    "    return (Xn, Yn), (Xe, Ye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_emp = np.array(sorted([graph.nodes[n]['year'] for n in graph.nodes]))\n",
    "years_emp_dist = np.cumsum(np.ones(shape=len(years_emp)))\n",
    "len(years_emp), len(years_emp_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=years_emp,\n",
    "                         y=years_emp_dist,\n",
    "                         name='empirical'))\n",
    "fig.add_trace(go.Scatter(x=years.Year,\n",
    "                         y=years['Year (cumsum)'],\n",
    "                         name='model'))\n",
    "fig.update_layout(title='Discoveries',\n",
    "                  xaxis_title='Year',\n",
    "                  yaxis_title='Number of discoveries',\n",
    "                  template='plotly_white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.write_image('fig1.svg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def update_network(change):\n",
    "    with fig.batch_update():\n",
    "        (Xn, Yn), (Xe, Ye) = graph_layout(model.graph,\n",
    "                                          [n for n in model.graph.nodes \n",
    "                                           if model.graph.nodes[n]['year']<=change.new])\n",
    "        fig.data[0].x = Xe\n",
    "        fig.data[0].y = Ye\n",
    "        fig.data[1].x = Xn\n",
    "        fig.data[1].y = Yn\n",
    "        fig.layout.title = model.graph.name + ', year: ' + str(change.new)\n",
    "        fig.update_xaxes(range=[-1.2,1.2])\n",
    "        fig.update_yaxes(range=[-1.2,1.2])\n",
    "\n",
    "nodes = list(model.graph.nodes)\n",
    "\n",
    "min_year = min([model.graph.nodes[n]['year'] for n in nodes])\n",
    "max_year = max([model.graph.nodes[n]['year'] for n in nodes])\n",
    "slider_network = widgets.IntSlider(value=min_year, min=min_year, max=max_year,\n",
    "                                   step=1, description='Year', continuous_update=True,\n",
    "                                   layout=Layout(width='auto'))\n",
    "slider_network.observe(update_network, names='value')\n",
    "display(slider_network)\n",
    "\n",
    "(Xn, Yn), (Xe, Ye) = graph_layout(model.graph,\n",
    "                                  [n for n in model.graph.nodes \n",
    "                                   if model.graph.nodes[n]['year']==min_year])\n",
    "\n",
    "trace1 = go.Scatter(x=Xe, y=Ye,# z=Ze, \n",
    "                    mode='lines', line=dict(color='gray', width=.5),\n",
    "                    hoverinfo='none')\n",
    "trace2 = go.Scatter(x=Xn, y=Yn,# z=Zn, \n",
    "                      mode='markers',\n",
    "                      marker=dict(symbol='circle', size=6,\n",
    "#                                color=group,\n",
    "                                  colorscale='Viridis',\n",
    "                                  line=dict(color='rgb(50,50,50)', width=0.5)),\n",
    "                      text=nodes, hoverinfo='text')\n",
    "axis = dict(showbackground=False,\n",
    "            showline=False,\n",
    "            zeroline=False,\n",
    "            showgrid=False,\n",
    "            showticklabels=False,\n",
    "            title='')\n",
    "fig = go.Figure(data=[trace1, trace2],\n",
    "                layout=go.Layout(title=topic + ', year: ' + str(min_year),\n",
    "                                 width=600,#1000,\n",
    "                                 height=600,\n",
    "                                 showlegend=False,\n",
    "                                 scene=dict(xaxis=dict(axis),\n",
    "                                            yaxis=dict(axis),\n",
    "                                            zaxis=dict(axis),),\n",
    "                                 hovermode='closest',\n",
    "                                 template='plotly_white'))\n",
    "fig = go.FigureWidget(fig)\n",
    "fig.update_xaxes(range=[-1.2,1.2])\n",
    "fig.update_yaxes(range=[-1.2,1.2])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "\n",
    "Too many connections in new nodes. So, try\n",
    "* restricting title words to uncommon words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "\n",
    "sim = lambda a,b: smp.cosine_similarity(a.transpose(), b.transpose())[0,0]\n",
    "\n",
    "nodes = list(model.graph.nodes)\n",
    "births = pd.DataFrame({'Node': nodes,\n",
    "                       'Year': [model.graph.nodes[n]['year'] for n in nodes]})\\\n",
    "           .sort_values(by=['Year'])\\\n",
    "           .reset_index(drop=True)\n",
    "births['Similarity (neighbor)'] = [[sim(model.vectors[:,nodes.index(births.iloc[i].Node)],\n",
    "                                        model.vectors[:,nodes.index(neighbor)])\n",
    "                                    for neighbor in it.chain(model.graph.successors(births.iloc[i].Node),\n",
    "                                                             model.graph.predecessors(births.iloc[i].Node))\n",
    "                                    if model.graph.nodes[neighbor]['year'] <= births.iloc[i].Year]\n",
    "                                   for i in births.index]\n",
    "births"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_y = 180\n",
    "\n",
    "def update_similarity(change):\n",
    "    with fig.batch_update():\n",
    "        fig.data[1].x = [j for i in births[births.Year<=change.new]['Similarity (neighbor)']\n",
    "                         for j in i]\n",
    "        fig.data[2].x = model.record['Similarity (parent)'][model.record.Year == change.new]\n",
    "        fig.update_xaxes(range=[0,1])\n",
    "        fig.update_yaxes(range=[0,max_y])\n",
    "\n",
    "min_year = min(model.record.Year)\n",
    "max_year = max(model.record.Year)\n",
    "slider = widgets.IntSlider(value=min_year, min=min_year, max=max_year,\n",
    "                           step=1, description='Year', continuous_update=True,\n",
    "                           layout=Layout(width='auto'))\n",
    "slider.observe(update_similarity, names='value')\n",
    "display(slider)\n",
    "\n",
    "fig = go.FigureWidget()\n",
    "fig.add_trace(go.Histogram(x=neighbors,\n",
    "                           name='empirical'))\n",
    "fig.add_trace(go.Histogram(x=[j for i in births[births.Year<=min_year+50]['Similarity (neighbor)']\n",
    "                              for j in i],\n",
    "                           name='model (neighbor)'))\n",
    "fig.add_trace(go.Histogram(x=model.record[model.record.Year==min_year]['Similarity (parent)'],\n",
    "                           name='model (parent)'))\n",
    "fig.update_layout(title='Cosine similarity', template='plotly_white',\n",
    "                  xaxis_title='cosine similarity', yaxis_title='number of edges')\n",
    "fig.update_xaxes(range=[0,1])\n",
    "fig.update_yaxes(range=[0,max_y])\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.subplot(121)\n",
    "sns.distplot(neighbors)\n",
    "x = np.linspace(min(neighbors), max(neighbors), 100)\n",
    "mu, std = sp.stats.norm.fit(neighbors)\n",
    "plt.plot(x, sp.stats.norm.pdf(x, mu, std))\n",
    "sns.distplot(non_neighbors)\n",
    "plt.title(topic + ' (prior)')\n",
    "plt.legend([f\"fit-neighbors (m={mu:.2f}; s={std:.2f})\", 'neighbors', 'non-neighbors'])\n",
    "plt.xlabel('cos similarity');\n",
    "plt.xlim([-.2,1.2])\n",
    "plt.subplot(122)\n",
    "neighbors_model = neighbor_similarity(model.graph, model.vectors)\n",
    "non_neighbors_model = non_neighbor_similarity(model.graph, model.vectors)\n",
    "sns.distplot(neighbors_model)\n",
    "x = np.linspace(min(neighbors_model), max(neighbors_model), 100)\n",
    "mu, std = sp.stats.norm.fit(neighbors_model)\n",
    "plt.plot(x, sp.stats.norm.pdf(x, mu, std))\n",
    "sns.distplot(non_neighbors_model)\n",
    "plt.title(topic + ' (model)')\n",
    "plt.legend([f\"fit-neighbors (m={mu:.2f}; s={std:.2f})\", 'neighbors', 'non-neighbors'])\n",
    "plt.xlabel('cos similarity')\n",
    "plt.xlim([-.2,1.2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.subplot(121)\n",
    "bin_size=25\n",
    "years = [graph.nodes[node]['year'] for node in graph.nodes]\n",
    "sns.distplot(years, bins=bin_size, rug=True, kde=False)\n",
    "hist, bin_edges = np.histogram(years, bins=bin_size)\n",
    "popt, pcov = sp.optimize.curve_fit(lambda x,a,b: a*pow(b,x), bin_edges[1:], hist)\n",
    "x = np.linspace(min(years), max(years), 100)\n",
    "sns.lineplot(x=x, y=popt[0]*pow(popt[1],x))\n",
    "plt.legend([f\"a*b^x; a={popt[0]:.1e}, b={popt[1]:.4f}\"])\n",
    "plt.title('prior')\n",
    "plt.ylabel('discoveries')\n",
    "plt.xlabel('year');\n",
    "\n",
    "plt.subplot(122)\n",
    "years = [model.graph.nodes[node]['year'] for node in model.graph.nodes]\n",
    "sns.distplot(years, bins=bin_size, rug=True, kde=False)\n",
    "hist, bin_edges = np.histogram(years, bins=bin_size)\n",
    "popt, pcov = sp.optimize.curve_fit(lambda x,a,b: a*pow(b,x), bin_edges[1:], hist)\n",
    "x = np.linspace(min(years), max(years), 100)\n",
    "sns.lineplot(x=x, y=popt[0]*pow(popt[1],x))\n",
    "plt.legend([f\"a*b^x; a={popt[0]:.1e}, b={popt[1]:.4f}\"])\n",
    "plt.title('model')\n",
    "plt.ylabel('discoveries')\n",
    "plt.xlabel('year');\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "bin_size=25\n",
    "years = [graph.nodes[node]['year'] for node in graph.nodes]\n",
    "sns.distplot(years, bins=bin_size, rug=True, kde=False, hist=False)\n",
    "# hist, bin_edges = np.histogram(years, bins=bin_size)\n",
    "# popt, pcov = sp.optimize.curve_fit(lambda x,a,b: a*pow(b,x), bin_edges[1:], hist)\n",
    "# x = np.linspace(min(years), max(years), 100)\n",
    "# sns.lineplot(x=x, y=popt[0]*pow(popt[1],x))\n",
    "sns.lineplot(x=sorted(years),\n",
    "             y=np.sum(np.array([sorted(years)]).transpose() < np.array([sorted(years)]), axis=0))\n",
    "\n",
    "years = [model.graph.nodes[node]['year'] for node in model.graph.nodes]\n",
    "sns.distplot(years, bins=bin_size, rug=True, kde=False, hist=False)\n",
    "hist, bin_edges = np.histogram(years, bins=bin_size)\n",
    "# popt_model, pcov = sp.optimize.curve_fit(lambda x,a,b: a*pow(b,x), bin_edges[1:], hist)\n",
    "# x = np.linspace(min(years), max(years), 100)\n",
    "# sns.lineplot(x=x, y=popt_model[0]*pow(popt_model[1],x))\n",
    "sns.lineplot(x=sorted(years),\n",
    "             y=np.sum(np.array([sorted(years)]).transpose() < np.array([sorted(years)]), axis=0))\n",
    "\n",
    "plt.legend([#f\"prior: a*b^x; a={popt[0]:.1e}, b={popt[1]:.4f}\",\n",
    "            f\"prior: count\",\n",
    "            #f\"model: a*b^x; a={popt_model[0]:.1e}, b={popt_model[1]:.4f}\",\n",
    "            f\"model: count\"])\n",
    "plt.ylabel('discoveries')\n",
    "plt.xlabel('year');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "fit.plot_pdf()\n",
    "fit.power_law.plot_pdf()\n",
    "plt.title(f\"empirical xmin={fit.xmin:.1e}, α={fit.alpha:.1f}\");\n",
    "plt.subplot(122)\n",
    "fit_model = powerlaw.Fit(model.vectors.data)\n",
    "fit_model.plot_pdf()\n",
    "fit_model.power_law.plot_pdf()\n",
    "plt.title(f\"model xmin={fit_model.xmin:.1e}, α={fit_model.alpha:.1f}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=np.abs(yd), y=wd, kind='reg',\n",
    "              marginal_kws=dict(bins=15, rug=True))\n",
    "plt.xlabel('Δyear')\n",
    "plt.ylabel('manhattan distance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_rows = 4\n",
    "plt.figure(figsize=(16,n_rows*6))\n",
    "\n",
    "# wd = word_diffs(graph, tfidf)\n",
    "# yd = year_diffs(graph)\n",
    "\n",
    "plt.subplot(n_rows,2,1)\n",
    "sns.distplot(yd)\n",
    "plt.title(topic + ' prior')\n",
    "plt.xlabel('year difference')\n",
    "\n",
    "plt.subplot(n_rows,2,2)\n",
    "yd_model = year_diffs(model.graph)\n",
    "sns.distplot(yd_model)\n",
    "plt.title(topic + ' model')\n",
    "plt.xlabel('year difference');\n",
    "\n",
    "plt.subplot(n_rows,2,3)\n",
    "sns.scatterplot(x=np.abs(yd), y=wd)\n",
    "slope, intercept, r, p, stderr = sp.stats.linregress(np.abs(yd), wd)\n",
    "x = np.linspace(0, max(yd), 100)\n",
    "sns.lineplot(x, np.multiply(slope, x) + intercept)\n",
    "plt.title(f\"slope={slope:.2f}; r={r:.2f}; p={p:.1e} (prior)\")\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('manhattan distance');\n",
    "\n",
    "plt.subplot(n_rows,2,4)\n",
    "sns.distplot(wd)\n",
    "mu, std = sp.stats.norm.fit(wd)\n",
    "x = np.linspace(min(wd), max(wd), 100)\n",
    "plt.plot(x, sp.stats.norm.pdf(x, mu, std))\n",
    "plt.xlabel('manhattan distance')\n",
    "plt.ylabel('probability distribution');\n",
    "plt.title(f\"μ={mu:.2}, σ={std:.2} (prior)\")\n",
    "\n",
    "wd_model = word_diffs(model.graph, model.vectors)\n",
    "yd_model = year_diffs(model.graph)\n",
    "neighbors_model = neighbor_similarity(model.graph, model.vectors)\n",
    "\n",
    "plt.subplot(n_rows,2,5)\n",
    "sns.scatterplot(x=np.abs(yd_model), y=wd_model)\n",
    "slope, intercept, r, p, stderr = sp.stats.linregress(np.abs(yd_model), wd_model)\n",
    "x = np.linspace(0, max(np.abs(yd_model)), 100)\n",
    "sns.lineplot(x, np.multiply(slope, x) + intercept)\n",
    "plt.title(f\"slope={slope:.2f}; r={r:.2f}; p={p:.1e} (model)\")\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('manhattan distance');\n",
    "\n",
    "plt.subplot(n_rows,2,6)\n",
    "sns.distplot(wd_model)\n",
    "mu, std = sp.stats.norm.fit(wd_model)\n",
    "x = np.linspace(min(wd_model), max(wd_model), 100)\n",
    "plt.plot(x, sp.stats.norm.pdf(x, mu, std))\n",
    "plt.xlabel('manhattan distance')\n",
    "plt.ylabel('probability distribution');\n",
    "plt.title(f\"μ={mu:.2}, σ={std:.2} (model)\");\n",
    "\n",
    "plt.subplot(n_rows,2,7)\n",
    "sns.scatterplot(x=np.abs(yd), y=neighbors)\n",
    "slope, intercept, r, p, stderr = sp.stats.linregress(np.abs(yd), neighbors)\n",
    "x = np.linspace(0, max(yd), 100)\n",
    "sns.lineplot(x, np.multiply(slope, x) + intercept)\n",
    "plt.title(f\"slope={slope:.2f}; r={r:.2f}; p={p:.1e} (prior)\")\n",
    "plt.xlabel('Δyear')\n",
    "plt.ylabel('cosine similarity');\n",
    "\n",
    "plt.subplot(n_rows,2,8)\n",
    "sns.scatterplot(x=np.abs(yd_model), y=neighbors_model)\n",
    "slope, intercept, r, p, stderr = sp.stats.linregress(np.abs(yd_model), neighbors_model)\n",
    "x = np.linspace(0, max(np.abs(yd_model)), 100)\n",
    "sns.lineplot(x, np.multiply(slope, x) + intercept)\n",
    "plt.title(f\"slope={slope:.2f}; r={r:.2f}; p={p:.1e} (model)\")\n",
    "plt.xlabel('Δyear')\n",
    "plt.ylabel('cosine similarity');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.scatterplot(x='index', y='weight',\n",
    "                data=pd.DataFrame({'index': model.vectors.indices,\n",
    "                                   'weight': model.vectors.data}))\n",
    "plt.ylim([-.1,1.1]);\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_distribution(model.vectors.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "nx.draw_networkx(graph, node_color=['r' if graph.nodes[n]['year']<-500 else 'b'\n",
    "                                    for n in graph.nodes])\n",
    "plt.title('original graph')\n",
    "plt.subplot(122)\n",
    "nx.draw_networkx(model.graph, node_color=['r' if model.graph.nodes[n]['year']<-500 else 'b'\n",
    "                                          for n in model.graph.nodes])\n",
    "plt.title('new graph');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.distplot([d for _,d in graph.degree], bins=30)\n",
    "sns.distplot([d for _,d in model.graph.degree], bins=30)\n",
    "plt.legend(['prior', 'model'])\n",
    "plt.xlim([-10,110]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The point of this model is that one can model knowledge discovery as incremental changes on existing knowledge.\n",
    "\n",
    "The mutation model doesn't monotonically decrease similarity with parent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "205.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
