{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network measures\n",
    "\n",
    "### Local structures\n",
    "\n",
    "**Indegree**\n",
    "This is mostly a function of how Wikipedians revised the document and should largely be uniform across pages. The large values are likely pages with 'lists' of links.\n",
    "\n",
    "**Outdegree**\n",
    "This is 1st-order measure of an idea's influence.\n",
    "\n",
    "### Mesoscale structures\n",
    "\n",
    "**Clustering**\n",
    "These look equally clustered among the topics.\n",
    "\n",
    "**Centrality**\n",
    "This reveals the distribution of sources of ideas within a field.\n",
    "\n",
    "**Path lengths**\n",
    "\n",
    "**Rich-club coefficient**\n",
    "\n",
    "**Modularity**\n",
    "\n",
    "**Controllability**\n",
    "This is an nth-order measure of influence.\n",
    "\n",
    "**Observability**\n",
    "This is an nth-order measure of the inverse of influence.\n",
    "\n",
    "**Coreness**\n",
    "It seems that the more focused a topic is on a subtopic, the stronger the coreness. For example, genetics is heavily focused on DNA, and so it has high coreness. At the same time, in the field of economics, the concept of \"economics\" has high degree. Yet, it has low coreness because the field itself is heterogeneous, with major subfields such as \"macroeconomics\" and \"microeconomics\".\n",
    "\n",
    "**Characteristic path length**\n",
    "I'm not sure what path length reveals. Perhaps it is a measure of the heterogeneity in research? It describes how far one idea is to another, topologically. Cognitive science and earth science have ideas that are far away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..', 'module'))\n",
    "import wiki\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['anatomy', 'biochemistry']\n",
    "# topics = ['anatomy', 'biochemistry', 'cognitive science', 'evolutionary biology',\n",
    "#           'genetics', 'immunology', 'molecular biology', 'chemistry', 'biophysics',\n",
    "#           'energy', 'optics', 'earth science', 'geology', 'meteorology']#,\n",
    "#           'philosophy of language', 'philosophy of law', 'philosophy of mind',\n",
    "#           'philosophy of science', 'economics', 'accounting', 'education',\n",
    "#           'linguistics', 'law', 'psychology', 'sociology', 'electronics',\n",
    "#           'software engineering', 'robotics',\n",
    "#           'calculus', 'geometry', 'abstract algebra',\n",
    "#           'Boolean algebra', 'commutative algebra', 'group theory', 'linear algebra',\n",
    "#           'number theory', 'dynamical systems and differential equations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved = '/Users/harangju/Developer/data/wiki/graphs/dated/'\n",
    "networks = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    networks[topic] = wiki.Net()\n",
    "    networks[topic].load_graph(path_saved + topic + '.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved = '/Users/harangju/Developer/data/wiki/graphs/null-target/'\n",
    "num_nulls = 2\n",
    "null_targets = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    null_targets[topic] = []\n",
    "    for i in range(num_nulls):\n",
    "        network = wiki.Net()\n",
    "        network.load_graph(path_saved + topic + '-null-' + str(i) + '.pickle')\n",
    "        null_targets[topic].append(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Run analysis\n",
    "\n",
    "**NOTE:** Skip section if loading stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import bct\n",
    "from networkx.algorithms.cluster import clustering\n",
    "from networkx.algorithms import betweenness_centrality\n",
    "from networkx.convert_matrix import to_numpy_array\n",
    "pd.options.display.max_rows = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "measures = {'indegree': lambda g: [x[1] for x in g.in_degree],\n",
    "            'outdegree': lambda g: [x[1] for x in g.out_degree],\n",
    "            'clustering': lambda g: list(clustering(g).values()),\n",
    "            'centrality': lambda g: list(betweenness_centrality(g).values()),\n",
    "            'path-length': lambda g: [y for x in list(nx.shortest_path_length(g))\n",
    "                                      for y in list(x[1].values())],\n",
    "            'char-path-length': lambda g: bct.charpath(to_numpy_array(g))[0],\n",
    "            'modularity': lambda g: g.graph['modularity'],\n",
    "            'coreness': lambda g: g.graph['coreness_be']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['topic','measure','value'])\n",
    "for topic, network in networks.items():\n",
    "    print(topic, end=' ')\n",
    "    df = pd.concat([df] +\n",
    "                   [pd.DataFrame([[topic, measure, func(network.graph)]],\n",
    "                                 columns=['topic','measure','value'])\n",
    "                    for measure, func in measures.items()],\n",
    "                   ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for topic, null_networks in null_targets.items():\n",
    "    print(topic, end=' ')\n",
    "    for network in null_networks:\n",
    "        df = pd.concat([df] + \n",
    "                       [pd.DataFrame([[topic, measure+'-null', func(network.graph)]],\n",
    "                                     columns=['topic','measure','value'])\n",
    "                        for measure, func in measures.items()],\n",
    "                       ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%time df_expand = df.value\\\n",
    "              .apply(pd.Series)\\\n",
    "              .merge(df, left_index=True, right_index=True)\\\n",
    "              .drop('value', axis=1)\\\n",
    "              .melt(id_vars=['topic','measure'])\\\n",
    "              .drop('variable', axis=1)\\\n",
    "              .dropna()\n",
    "df_expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump((df, df_expand),\n",
    "            open('/Users/harangju/Developer/data/wiki/analysis/stats.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "df, df_expand = pickle.load(\n",
    "    open('/Users/harangju/Developer/data/wiki/analysis/stats.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df.topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot\n",
    "\n",
    "* nice plots [seaborn](https://seaborn.pydata.org/examples/index.html)\n",
    "* interactive [Bokeh](https://bokeh.pydata.org/en/latest/docs/gallery.html#gallery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cufflinks as cf\n",
    "# cf.go_offline()\n",
    "from ipywidgets import interact, widgets, Layout\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 12\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for stat in ['indegree', 'outdegree', 'clustering', 'centrality', 'path-length']:\n",
    "    fig = px.box(df_expand[(df_expand.measure==stat) | (df_expand.measure==stat+'-null')],\n",
    "                 x='topic', y='value', color='measure')\n",
    "    fig.update_layout(template='plotly_white')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for stat in ['coreness', 'modularity', 'char-path-length']:\n",
    "    fig = px.scatter(df_expand[(df_expand.measure==stat) |\\\n",
    "                               (df_expand.measure==stat+'-null')],\n",
    "                     x='topic', y='value', color='measure')\n",
    "    fig.update_layout(template='plotly_white')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_expand\\\n",
    "        .groupby(['topic', 'measure'], as_index=False)\\\n",
    "        .mean()\\\n",
    "        .pivot(index='topic', columns='measure', values='value')\\\n",
    "        .reset_index()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=data['coreness-null'],\n",
    "                         y=data['coreness'],\n",
    "                         mode='markers',\n",
    "                         name='coreness'))\n",
    "fig.add_trace(go.Scatter(x=data['modularity-null'],\n",
    "                         y=data['modularity'],\n",
    "                         mode='markers',\n",
    "                         name='modularity'))\n",
    "fig.add_trace(go.Scatter(x=[0,1], y=[0,1],\n",
    "                         mode='lines',\n",
    "                         line=dict(dash='dash'),\n",
    "                         name='1:1'))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  width=500, height=500,\n",
    "                  xaxis=dict(title='null',\n",
    "                             range=[0,1]),\n",
    "                  yaxis=dict(title='real',\n",
    "                             range=[0,1],\n",
    "                             scaleanchor='x',\n",
    "                             scaleratio=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures in growing networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comm_t = pd.DataFrame()\n",
    "for topic, network in networks.items():\n",
    "    print(topic, end=' ')\n",
    "    comm_t = pd.concat([comm_t] +\n",
    "                       [pd.DataFrame([[topic,\n",
    "                                       node,\n",
    "                                       network.graph.nodes[node]['year'],\n",
    "                                       network.graph.nodes[node]['community'],\n",
    "                                       network.graph.nodes[node]['core_be'],\n",
    "                                       network.graph.nodes[node]['core_rb'],\n",
    "                                       1]],\n",
    "                                     columns=['topic','node','year',\n",
    "                                              'comm','core_be','core_rb',\n",
    "                                              'count'])\n",
    "                        for node in network.graph.nodes],\n",
    "                       ignore_index=True)\n",
    "comm_t = comm_t.merge(comm_t.groupby(['topic','comm'])['count'].sum(),\n",
    "                      on=['topic','comm'],\n",
    "                      suffixes=('','_topic_comm'))\\\n",
    "               .merge(comm_t.groupby(['topic','core_be'])['count'].sum(),\n",
    "                      on=['topic','core_be'],\n",
    "                      suffixes=('','_topic_core_be'))\\\n",
    "               .sort_values(by=['topic','year'])\\\n",
    "               .reset_index(drop=True)\n",
    "comm_t['comm_count'] = comm_t.groupby(['topic','comm'])['count']\\\n",
    "                             .transform(pd.Series.cumsum)\n",
    "comm_t['core_be_count'] = comm_t.groupby(['topic','core_be'])['count']\\\n",
    "                                .transform(pd.Series.cumsum)\n",
    "comm_t['comm_frac'] = comm_t['comm_count']/comm_t['count_topic_comm']\n",
    "comm_t['core_be_frac'] = comm_t['core_be_count']/comm_t['count_topic_core_be']\n",
    "comm_t = comm_t.drop(['count','count_topic_comm','count_topic_core_be'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Growth in core-periphery & modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in networks.keys():\n",
    "    fig = px.line(comm_t[comm_t.topic==topic],\n",
    "                     x='year', y='comm_count', color='comm')\n",
    "    fig.update_layout(template='plotly_white',\n",
    "                      title_text=topic,\n",
    "                      xaxis={'range': [0,2000]})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in networks.keys():\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=comm_t[(comm_t.topic==topic) &\\\n",
    "                                      (comm_t.core_be==0)]['year'],\n",
    "                             y=comm_t[(comm_t.topic==topic) &\\\n",
    "                                      (comm_t.core_be==0)]['core_be_count'],\n",
    "                             name='core_be = 0'))\n",
    "    fig.add_trace(go.Scatter(x=comm_t[(comm_t.topic==topic) &\\\n",
    "                                      (comm_t.core_be==1)]['year'],\n",
    "                             y=comm_t[(comm_t.topic==topic) &\\\n",
    "                                      (comm_t.core_be==1)]['core_be_count'],\n",
    "                             name='core_be = 1'))\n",
    "    fig.update_layout(template='plotly_white',\n",
    "                      title_text=topic,\n",
    "                      xaxis={'range': [0,2020]})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birth: core vs. periphery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "birth = pd.concat([pd.DataFrame([[comm_t.iloc[i].topic,\n",
    "                                  comm_t.iloc[i].node,\n",
    "                                  comm_t.iloc[i].year,\n",
    "                                  [c for c in \n",
    "                                   list(networks[comm_t.iloc[i].topic]\\\n",
    "                                        .graph.successors(comm_t.iloc[i].node)) + \n",
    "                                   list(networks[comm_t.iloc[i].topic]\\\n",
    "                                        .graph.predecessors(comm_t.iloc[i].node))\n",
    "                                   if networks[comm_t.iloc[i].topic].graph.nodes[c]['core_be']]\n",
    "                                 ]],\n",
    "                                columns=['topic','periphery','year','cores'])\n",
    "                   for i in range(len(comm_t.index))\n",
    "                   if not comm_t.iloc[i].core_be],\n",
    "                  ignore_index=True)\n",
    "birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "birth_exp = birth.cores.apply(pd.Series)\\\n",
    "                 .merge(birth, left_index=True, right_index=True)\\\n",
    "                 .drop(['cores'], axis=1)\\\n",
    "                 .melt(id_vars=['topic','periphery','year'], value_name='core')\\\n",
    "                 .drop('variable', axis=1)\\\n",
    "                 .dropna()\\\n",
    "                 .sort_values(by=['topic','year', 'periphery'])\\\n",
    "                 .reset_index(drop=True)\n",
    "birth_exp['core_year'] = [networks[birth_exp.iloc[i].topic].graph\\\n",
    "                          .nodes[birth_exp.iloc[i].core]['year']\n",
    "                          for i in range(len(birth_exp.index))]\n",
    "birth_exp['centrality'] = [df[df.topic==birth_exp.iloc[i].topic]\\\n",
    "                           [df.measure=='centrality'].value.values[0]\\\n",
    "                           [networks[birth_exp.iloc[i].topic].nodes.index(birth_exp.iloc[i].core)]\n",
    "                           for i in range(len(birth_exp.index))]\n",
    "birth_exp['indegree'] = [df[df.topic==birth_exp.iloc[i].topic]\\\n",
    "                           [df.measure=='indegree'].value.values[0]\\\n",
    "                           [networks[birth_exp.iloc[i].topic].nodes.index(birth_exp.iloc[i].core)]\n",
    "                           for i in range(len(birth_exp.index))]\n",
    "birth_exp['outdegree'] = [df[df.topic==birth_exp.iloc[i].topic]\\\n",
    "                           [df.measure=='outdegree'].value.values[0]\\\n",
    "                           [networks[birth_exp.iloc[i].topic].nodes.index(birth_exp.iloc[i].core)]\n",
    "                           for i in range(len(birth_exp.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birth_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for topic in networks.keys():\n",
    "    fig = px.scatter(birth_exp[birth_exp.topic==topic],\n",
    "                     x='year', y='core_year', color='outdegree')\n",
    "    fig.update_layout(template='plotly_white',\n",
    "                      title_text=topic,\n",
    "                      width=500, height=500,\n",
    "                      yaxis={'scaleanchor': 'x',\n",
    "                             'scaleratio': 1})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cores in communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_core = pd.concat([pd.DataFrame([[node,\n",
    "                                      graph.nodes[node]['year'],\n",
    "                                      graph.nodes[node]['community'],\n",
    "                                      graph.nodes[node]['community_core_be'],\n",
    "                                      1 if graph.nodes[node]['community_core_be']==0 else 0,\n",
    "                                      graph.graph['community_coreness_be']\\\n",
    "                                          [graph.nodes[node]['community']],\n",
    "                                      1\n",
    "                                     ]],\n",
    "                                    columns=['node','year','community','community_core',\n",
    "                                             'community_peri','community_coreness','count'])\n",
    "                       for node in graph.nodes],\n",
    "                      ignore_index=True)\\\n",
    "              .sort_values(by='year')\n",
    "comm_core = comm_core\\\n",
    "              .merge(comm_core.groupby(['community'])['count'].sum(),\n",
    "                     on=['community'],\n",
    "                     suffixes=('','_sum'))\n",
    "comm_core['core_count'] = comm_core.groupby(['community'])['community_core']\\\n",
    "                                             .transform(pd.Series.cumsum)\n",
    "comm_core['peri_count'] = comm_core.groupby(['community'])['community_peri']\\\n",
    "                                             .transform(pd.Series.cumsum)\n",
    "comm_core = comm_core.drop(['count', 'count_sum', 'community_core', 'community_peri'], axis=1)\n",
    "comm_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):#range(max([graph.nodes[n]['community'] for n in graph.nodes]) + 1):\n",
    "    fig = go.Figure()\n",
    "    data = comm_core[comm_core.community==i]\n",
    "    fig.add_trace(go.Scatter(x=data['year'],\n",
    "                             y=data['core_count'],\n",
    "                             mode='lines',\n",
    "                             name='# cores'))\n",
    "    fig.add_trace(go.Scatter(x=data['year'],\n",
    "                             y=data['peri_count'],\n",
    "                             mode='lines',\n",
    "                             name='# periphery'))\n",
    "    fig.update_layout(template='plotly_white',\n",
    "                      title_text=f\"community {i+1}\",\n",
    "                      height=400)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
