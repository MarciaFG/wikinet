{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..', 'module'))\n",
    "import wiki\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics = ['anatomy', 'biochemistry', 'cognitive science', 'evolutionary biology',\n",
    "          'genetics', 'immunology', 'molecular biology', 'chemistry', 'biophysics',\n",
    "          'energy', 'optics', 'earth science', 'geology', 'meteorology',\n",
    "          'philosophy of language', 'philosophy of law', 'philosophy of mind',\n",
    "          'philosophy of science', 'economics', 'accounting', 'education',\n",
    "          'linguistics', 'law', 'psychology', 'sociology', 'electronics',\n",
    "          'software engineering', 'robotics',\n",
    "          'calculus', 'geometry', 'abstract algebra',\n",
    "          'Boolean algebra', 'commutative algebra', 'group theory', 'linear algebra',\n",
    "          'number theory', 'dynamical systems and differential equations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_saved = os.path.join('/','Users','harangju','Developer',\n",
    "                          'data','wiki','graphs','dated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_fig = os.path.join('/','Users','harangju','Box Sync',\n",
    "                        'Research','my papers','wikipedia','results')\n",
    "save_fig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_plot = '4 fields'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# topics = ['earth science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import wiki\n",
    "\n",
    "networks = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    networks[topic] = wiki.Net(\n",
    "        path_graph=os.path.join(path_saved, topic + '.pickle'),\n",
    "        path_barcodes=os.path.join(path_saved, topic + '.barcode')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_null = '/Users/harangju/Developer/data/wiki/graphs/null-target/'\n",
    "num_nulls = 10\n",
    "null_targets = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    null_targets[topic] = [None for i in range(num_nulls)]\n",
    "    for i in range(num_nulls):\n",
    "        null_targets[topic][i] = wiki.Net(path_graph=path_null + topic + '-null-' + str(i) + '.pickle',\n",
    "                                          path_barcodes=path_null + topic + '-null-' + str(i) + '.barcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_null = '/Users/harangju/Developer/data/wiki/graphs/null-year/'\n",
    "num_nulls = 10\n",
    "null_years = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    null_years[topic] = [None for i in range(num_nulls)]\n",
    "    for i in range(num_nulls):\n",
    "        null_years[topic][i] = wiki.Net(path_graph=path_null + topic + '-null-' + str(i) + '.pickle',\n",
    "                                        path_barcodes=path_null + topic + '-null-' + str(i) + '.barcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "path_analysis = '/Users/harangju/Developer/data/wiki/analysis/'\n",
    "df = pickle.load(open(path_analysis+'stats.pickle', 'rb'))\n",
    "df_expand = pickle.load(open(path_analysis+'stats_expand.pickle', 'rb'))\n",
    "df.topic = df.topic.astype('object')\n",
    "df.measure = df.measure.astype('object')\n",
    "df_expand.topic = df_expand.topic.astype('object')\n",
    "df_expand.measure = df_expand.measure.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mean = df_expand\\\n",
    "    .groupby(['topic', 'measure'], as_index=False)\\\n",
    "    .mean()\\\n",
    "    .pivot(index='topic', columns='measure', values='value')\\\n",
    "    .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_mean['coreness-null-target'],\n",
    "                         y=df_mean['coreness'],\n",
    "                         mode='markers+text',\n",
    "                         name='coreness',\n",
    "                         text=df_mean['topic'],\n",
    "                         textposition='top left'))\n",
    "fig.add_trace(go.Scatter(x=[0,1], y=[0,1],\n",
    "                         mode='lines',\n",
    "                         line=dict(dash='dash'),\n",
    "                         name='1:1'))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  title='coreness',\n",
    "                  width=800, height=800,\n",
    "                  xaxis=dict(title='null',\n",
    "                             range=[.3,.8]),\n",
    "                  yaxis=dict(title='real',\n",
    "                             range=[.5,1],\n",
    "                             scaleanchor='x',\n",
    "                             scaleratio=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_plot = '4 fields'\n",
    "fig.write_image(os.path.join(path_fig, path_plot, 'coreness.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_mean['modularity-null-target'],\n",
    "                         y=df_mean['modularity'],\n",
    "                         mode='markers+text',\n",
    "                         name='modularity',\n",
    "                         text=df_mean['topic'],\n",
    "                         textposition='bottom right'))\n",
    "fig.add_trace(go.Scatter(x=[0,1], y=[0,1],\n",
    "                         mode='lines',\n",
    "                         line=dict(dash='dash'),\n",
    "                         name='1:1'))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  title='modularity',\n",
    "                  width=900, height=900,\n",
    "                  xaxis=dict(title='null',\n",
    "                             range=[.1,.7]),\n",
    "                  yaxis=dict(title='real',\n",
    "                             range=[.1,.7],\n",
    "                             scaleanchor='x',\n",
    "                             scaleratio=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_plot = '4 fields'\n",
    "fig.write_image(os.path.join(path_fig, path_plot, 'modularity.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing along network statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def distance_to_line(a,b,c,x,y): # ax+by+c=0, (x,y)\n",
    "    return abs(a*x + b*y+ c) / np.sqrt(a**2 + b**2)\n",
    "\n",
    "def closest_point_on_line_to_point(m,b,x,y): # y=mx+b, (x,y)\n",
    "    _x = (y + m*x - b)/(2*m)\n",
    "    _y = m*_x + b\n",
    "    return _x, _y\n",
    "\n",
    "def distance_along_closest_point(m,b,x,y):\n",
    "    _x, _y = closest_point_on_line_to_point(m,b,x,y)\n",
    "    return np.sqrt(_x**2 + _y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mean = df_mean.set_index('topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coreness_line = sp.stats.linregress(df_mean['coreness-null-target'], df_mean['coreness'])\n",
    "coreness_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network_stats = pd.DataFrame(\n",
    "    {\n",
    "        'topic': topics,\n",
    "        'modularity (adjusted)': \n",
    "            [distance_to_line(-1,1,0,\n",
    "                              df_mean.loc[t]['modularity-null-target'],\n",
    "                              df_mean.loc[t]['modularity'])\n",
    "             for t in topics],\n",
    "        'coreness (adjusted)': \n",
    "            [distance_along_closest_point(coreness_line[0], coreness_line[1],\n",
    "                                          df_mean.loc[t]['coreness-null-target'],\n",
    "                                          df_mean.loc[t]['coreness'])\n",
    "                     for t in topics]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp.stats.linregress(network_stats['modularity (adjusted)'], network_stats['coreness (adjusted)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# network_stats.sort_values('modularity (adjusted)', axis=0, ascending=False)\n",
    "# network_stats.sort_values('coreness', axis=0, ascending=False)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=network_stats['modularity (adjusted)'],\n",
    "                         y=network_stats['coreness (adjusted)'],\n",
    "                         text=network_stats['topic'],\n",
    "                         mode='markers'))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  xaxis={'title': 'modularity (adjusted)'},\n",
    "                  yaxis={'title': 'coreness (adjusted)'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network_stats.sort_values('modularity (adjusted)', ascending=False)['topic'].values,\\\n",
    "network_stats.sort_values('coreness (adjusted)', ascending=False)['topic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'ordered by adjusted modularity':\n",
    "                  network_stats.sort_values('modularity (adjusted)', ascending=False)['topic'].values,\n",
    "              'ordered by adjusted coreness':\n",
    "                  network_stats.sort_values('coreness (adjusted)', ascending=False)['topic'].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cavity statistics\n",
    "\n",
    "More dense connections\n",
    "In harder sciences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "# path_fig = '/Users/harangju/Box Sync/Research/my papers/wikipedia/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "barcodes = pd.concat([network.barcodes.assign(topic=topic)\\\n",
    "                                      .assign(type='real')\\\n",
    "                                      .assign(null=0)\n",
    "                      for topic, network in networks.items()] +\n",
    "                     [network.barcodes.assign(topic=topic)\\\n",
    "                                      .assign(type='targets')\\\n",
    "                                      .assign(null=i)\n",
    "                      for topic, nulls in null_targets.items()\n",
    "                          for i, network in enumerate(nulls)] +\n",
    "                     [network.barcodes.assign(topic=topic)\\\n",
    "                                      .assign(type='years')\\\n",
    "                                      .assign(null=i)\n",
    "                      for topic, nulls in null_years.items()\n",
    "                          for i, network in enumerate(nulls)],\n",
    "                     ignore_index=True, sort=False)\n",
    "barcodes = barcodes[barcodes.lifetime!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "null_count = barcodes\\\n",
    "    .groupby(['type','topic','dim'], as_index=False)['null'].max()\n",
    "null_count.null = null_count.null + 1\n",
    "null_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dim_count = barcodes\\\n",
    "    .assign(count=1)\\\n",
    "    .groupby(['type','topic','dim'], as_index=False)['count'].sum()\\\n",
    "    .sort_values('type', axis=0, ascending=True)\n",
    "dim_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dims = pd\\\n",
    "    .merge(dim_count, null_count, how='left', left_on=['type','topic','dim'], right_on=['type','topic','dim'])\\\n",
    "    .sort_values(by=['type','topic','dim'])\\\n",
    "    .reset_index(drop=True)\\\n",
    "    .rename(columns={'count': 'dim_count', 'null': 'null_count'})\n",
    "dims['dim_count_norm'] = dims['dim_count'] / dims.null_count\n",
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.box(dims[dims.type=='real'], x='dim', y='dim_count_norm')\n",
    "for topic in pd.unique(dims['topic']):\n",
    "    data = dims[(dims['type']=='real') & (dims['topic']==topic)].sort_values(by='dim')\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data['dim'], y=data['dim_count_norm'], name=topic,\n",
    "        mode='markers+lines', visible='legendonly'\n",
    "    ))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  title_text='Dimensionality',\n",
    "                  yaxis={'range': [0,10000]})\n",
    "fig.update_traces(marker={'size': 3}, line={'width': 1})\n",
    "fig.show()\n",
    "# fig.write_image(os.path.join(path_fig, path_plot, 'dimensionality_real.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "dim_stats = pd.DataFrame(dims\\\n",
    "    .groupby(['type','topic'])['dim_count_norm'].idxmax())\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={'dim_count_norm': 'dim_mode_idx'})\n",
    "dim_stats['mode'] = dims.iloc[dim_stats['dim_mode_idx']]['dim'].values\n",
    "dim_stats = dim_stats.drop('dim_mode_idx', axis=1)\n",
    "dim_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg = dims\\\n",
    "    .assign(dimXcount=dims['dim'] * dims['dim_count_norm'])\\\n",
    "    .groupby('topic', as_index=False)[['dim_count_norm','dimXcount']].sum()\\\n",
    "    .rename(columns={'dim_count_norm': 'dim_count_norm_sum'})\n",
    "dim_stats['mean'] = avg['dimXcount'] / avg['dim_count_norm_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 111\n",
    "dim_stats[dim_stats['type']=='real']\\\n",
    "    .sort_values(['mean'])\\\n",
    "    .reset_index()\\\n",
    "    .drop(['type','index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we say that the dimensionality of cavities reveals the **complexity of the information**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "big_net = wiki.Net(path_graph=os.path.join(path_saved, 'big_network.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix(big_net.graph)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "big_net.graph['Commercial law']['Unfair competition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "big_net.graph['Unfair competition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(big_net.graph.nodes).index('Commercial law'), list(big_net.graph.nodes).index('Unfair competition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A[0,1], A[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation: `a[i,j]` means that `i` points to `j` and that page `i` is linked to from page `j` in Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Births"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        'topic': topics,\n",
    "        'year (mean)': [np.mean(list(nx.get_node_attributes(network.graph, 'year').values()))\n",
    "                        for network in networks.values()],\n",
    "        'year (std)': [np.std(list(nx.get_node_attributes(network.graph, 'year').values()))\n",
    "                       for network in networks.values()]\n",
    "    }\n",
    ").sort_values(['year (mean)'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controllability\n",
    "\n",
    "Is there a spectrum of controllability in nodes & topics (as summarized over nodes) from \"pure\" to \"applied\" fields?\n",
    "\n",
    "Make sure to check outdegree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "# import control\n",
    "\n",
    "def gramians(A, M):\n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A: scipy.sparse.csc_matrix or csr_matrix\n",
    "        turns csr_matrix into csc_matrix\n",
    "        A[i,j] should have j->i\n",
    "    M: int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    CG, OG: scipy.sparse.csc_matrix\n",
    "        controllability & observability Gramians\n",
    "    '''\n",
    "    if isinstance(A, sp.sparse.csr_matrix):\n",
    "        A = A.transpose()\n",
    "    val, vec = sp.sparse.linalg.eigs(A.transpose())\n",
    "    # pre-calculate A^m and (A^T)^m\n",
    "    Anorm = A / (1 + val[0])\n",
    "    AnormT = Anorm.transpose().tocsc()\n",
    "    Am = [sp.sparse.identity(A.shape[0], dtype=np.float64, format='csc'), Anorm]\n",
    "    ATm = [sp.sparse.identity(A.shape[0], dtype=np.float64, format='csc'), AnormT]\n",
    "    for m in range(2,M+1):\n",
    "        Am += [Am[-1] * Anorm]\n",
    "        ATm += [ATm[-1] * AnormT]\n",
    "    # calculate controllability & observability Gramians\n",
    "    CG = Am[0] * ATm[0]\n",
    "    OG = ATm[0] * Am[0]\n",
    "    for m in range(1,M+1):\n",
    "        print('G ' + str(m))\n",
    "        CG += Am[m] * ATm[m]\n",
    "        OG += ATm[m] * Am[m]\n",
    "    return CG, OG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Gramians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes = list(big_net.graph.nodes)\n",
    "grams = pd.DataFrame({'node': nodes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M = 5\n",
    "for m in range(1,M+1):\n",
    "    print(f\"m={m}\")\n",
    "    CG, OG = gramians(A, m)\n",
    "    grams[f\"CG_{m}\"] = CG.diagonal()\n",
    "    grams[f\"OG_{m}\"] = OG.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del CG, OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grams = grams.set_index('node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "path_save = os.path.join('/','Users','harangju','Developer','data','wiki','analysis')\n",
    "pickle.dump(grams, open(os.path.join(path_save, 'grams.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "path_save = os.path.join('/','Users','harangju','Developer','data','wiki','analysis')\n",
    "grams = pickle.load(open(os.path.join(path_save, 'grams.pickle'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllability statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_rows = 20\n",
    "pd.DataFrame(\n",
    "    np.concatenate(\n",
    "        [[grams.sort_values(f\"OG_{m}\", ascending=False).iloc[0:num_rows].index.values]\n",
    "         for m in range(1,M+1)],\n",
    "        axis=0\n",
    "    ).transpose(),\n",
    "    columns=[f\"OG_{m}\" for m in range(1,M+1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.options.display.max_rows = 100\n",
    "num_rows = 20\n",
    "pd.DataFrame(\n",
    "    np.concatenate(\n",
    "        [[grams.sort_values(f\"CG_{m}\", ascending=False).iloc[0:num_rows].index.values]\n",
    "         for m in range(1,M+1)],\n",
    "        axis=0\n",
    "    ).transpose(),\n",
    "    columns=[f\"CG_{m}\" for m in range(1,M+1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node statistics averaged in topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grams_topics = pd.DataFrame()\n",
    "for topic in topics:\n",
    "    vals = {key: 0 for key in grams.columns.values}\n",
    "    for key in vals:\n",
    "        vals[key] = np.mean([grams.loc[node][key] for node in networks[topic].graph.nodes])\n",
    "    grams_topics = pd.concat([grams_topics,\n",
    "                              pd.DataFrame([[topic] + [v for k,v in vals.items()]], \n",
    "                                           columns=['topic']+list(vals.keys()))\n",
    "                             ])\n",
    "grams_topics = grams_topics.set_index('topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OG = pd.DataFrame(\n",
    "    np.concatenate(\n",
    "        [[grams_topics.sort_values(f\"OG_{m}\", ascending=False).index.values]\n",
    "         for m in range(1,M+1)],\n",
    "        axis=0\n",
    "    ).transpose(),\n",
    "    columns=[f\"OG_{m}\" for m in range(1,M+1)]\n",
    ")\n",
    "OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_fig = os.path.join('/','Users','harangju','Box Sync','Research','my papers','wikipedia','results')\n",
    "path_plot = '4 fields'\n",
    "OG.to_csv(os.path.join(path_fig, path_plot, 'OG.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CG = pd.DataFrame(\n",
    "    np.concatenate(\n",
    "        [[grams_topics.sort_values(f\"CG_{m}\", ascending=False).index.values]\n",
    "         for m in range(1,M+1)],\n",
    "        axis=0\n",
    "    ).transpose(),\n",
    "    columns=[f\"CG_{m}\" for m in range(1,M+1)]\n",
    ")\n",
    "CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_fig = os.path.join('/','Users','harangju','Box Sync','Research','my papers','wikipedia','results')\n",
    "path_plot = '4 fields'\n",
    "CG.to_csv(os.path.join(path_fig, path_plot, 'CG.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cavity vs controllability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z = pd.DataFrame({'topic': topics,\n",
    "                  'weights_mean': [np.mean([big_net.graph[n][s]['weight']\n",
    "                                            for n in networks[topic].graph.nodes\n",
    "                                            for s in big_net.graph[n]])\n",
    "                                   for topic in topics],\n",
    "                  'weights_sum': [np.sum([big_net.graph[n][s]['weight']\n",
    "                                            for n in networks[topic].graph.nodes\n",
    "                                            for s in big_net.graph[n]])\n",
    "                                   for topic in topics]\n",
    "                 })\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = np.array([grams_topics.loc[t]['CG_5'] for t in topics]).astype(np.float64)#.reshape((-1,1))\n",
    "x = dim_stats[dim_stats['type']=='real']\\\n",
    "    .sort_values(['mean'])\\\n",
    "    .reset_index()\\\n",
    "    .drop(['type','index'], axis=1)\\\n",
    "    .set_index('topic')\n",
    "x = np.array([x.loc[t]['mean'] for t in topics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_y = sp.stats.linregress(x, y)\n",
    "z_y_mean = sp.stats.linregress(z['weights_mean'].values, y)\n",
    "z_y_sum = sp.stats.linregress(z['weights_sum'].values, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_y, z_y_mean, z_y_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y,\n",
    "                         mode='markers', \n",
    "                         name='Fields',\n",
    "                         hovertext=topics))\n",
    "fig.add_trace(go.Scatter(x=np.linspace(min(x), max(x), num=100),\n",
    "                         y=np.linspace(min(x), max(x), num=100) * x_y[0] + x_y[1],\n",
    "                         mode='lines',\n",
    "                         name=f\"R^2={x_y[2]:.2f}, p={x_y[3]:.1e}\"))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  yaxis={'title': 'mean impulse response'},\n",
    "                  xaxis={'title': 'mean cavity dimension'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_fig = os.path.join('/','Users','harangju','Box Sync','Research',\n",
    "                        'my papers','wikipedia','results')\n",
    "path_plot = '4 fields'\n",
    "fig.write_image(os.path.join(path_fig, path_plot, 'cavity_dim_vs_ctrb.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result suggests that the more complex the relationships are defined between knowledge in a field the more influential that field is. I guess here, the controllability is averaged across nodes in a field, but I should try with the topic-summarized network. But I expect the same result to hold true--that the higher the dimensionality of knowledge, the more impact it has on the rest of the knowledge network. See the fields with low dimensionality. Those fields are 'biophysics'..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "node_stats = pd.DataFrame()\n",
    "for node in big_net.graph.nodes:\n",
    "    node_stats = pd.concat(\n",
    "        [\n",
    "            node_stats, \n",
    "            pd.DataFrame(\n",
    "                [[\n",
    "                    node,\n",
    "                    len(list(big_net.graph.successors(node))),\n",
    "                    [\n",
    "                        big_net.graph.edges[node,t]['weight'] \n",
    "                        for t in big_net.graph.successors(node)\n",
    "                    ],\n",
    "                    len(\n",
    "                        list(big_net.graph.successors(node)) + \\\n",
    "                        list(big_net.graph.predecessors(node))\n",
    "                    ),\n",
    "                    nx.clustering(big_net.graph, node)\n",
    "                ]],\n",
    "                columns=[\n",
    "                    'node',\n",
    "                    'outdegree',\n",
    "                    'weighted_outdegree',\n",
    "                    'degree',\n",
    "                    'clustering'\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "        ignore_index=True\n",
    "    )\n",
    "node_stats = node_stats.set_index('node')\n",
    "node_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controllability vs outdegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outdeg_ir1 = sp.stats.linregress(\n",
    "    [node_stats.loc[n].outdegree for n in big_net.graph.nodes],\n",
    "    [float(grams.loc[n].CG_1) for n in big_net.graph.nodes]\n",
    ")\n",
    "outdeg_ir2 = sp.stats.linregress(\n",
    "    [node_stats.loc[n].outdegree for n in big_net.graph.nodes],\n",
    "    [float(grams.loc[n].CG_2) for n in big_net.graph.nodes]\n",
    ")\n",
    "outdeg_ir3 = sp.stats.linregress(\n",
    "    [node_stats.loc[n].outdegree for n in big_net.graph.nodes],\n",
    "    [float(grams.loc[n].CG_3) for n in big_net.graph.nodes]\n",
    ")\n",
    "outdeg_ir4 = sp.stats.linregress(\n",
    "    [node_stats.loc[n].outdegree for n in big_net.graph.nodes],\n",
    "    [float(grams.loc[n].CG_4) for n in big_net.graph.nodes]\n",
    ")\n",
    "outdeg_ir5 = sp.stats.linregress(\n",
    "    [node_stats.loc[n].outdegree for n in big_net.graph.nodes],\n",
    "    [float(grams.loc[n].CG_5) for n in big_net.graph.nodes]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdeg_ir1, outdeg_ir2, outdeg_ir3, outdeg_ir4, outdeg_ir5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[node_stats.loc[n].outdegree for n in big_net.graph.nodes],\n",
    "        y=[float(grams.loc[n].CG_5) for n in big_net.graph.nodes],\n",
    "        mode='markers'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=400, height=400,\n",
    "    template='plotly_white',\n",
    "    title=f\"{outdeg_ir5.slope:.2f}x+{outdeg_ir5.intercept:.2f}; \"+\\\n",
    "          f\"r={outdeg_ir5.rvalue:.2f}, p={outdeg_ir5.pvalue:.2e}\",\n",
    "    xaxis={'title': 'mean outdegree'},\n",
    "    yaxis={'title': 'mean IR'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controllability vs degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_ir5 = sp.stats.linregress(\n",
    "    [node_stats.loc[n].degree for n in big_net.graph.nodes],\n",
    "    [float(grams.loc[n].CG_5) for n in big_net.graph.nodes]\n",
    ")\n",
    "deg_ir5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[degree.loc[n].degree for n in big_net.graph.nodes],\n",
    "        y=[float(grams.loc[n].CG_5) for n in big_net.graph.nodes],\n",
    "        mode='markers'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=400, height=400,\n",
    "    template='plotly_white',\n",
    "    title=f\"{deg_ir5.slope:.2f}x+{deg_ir5.intercept:.2f}; \"+\\\n",
    "          f\"r={deg_ir5.rvalue:.2f}, p={deg_ir5.pvalue:.2e}\",\n",
    "    xaxis={'title': 'degree'},\n",
    "    yaxis={'title': 'IR'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controllability vs clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clstr_ir5 = sp.stats.linregress(\n",
    "    [node_stats.loc[n].clustering for n in big_net.graph.nodes],\n",
    "    [float(grams.loc[n].CG_5) for n in big_net.graph.nodes]\n",
    ")\n",
    "clstr_ir5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[node_stats.loc[n].clustering for n in big_net.graph.nodes],\n",
    "        y=[float(grams.loc[n].CG_5) for n in big_net.graph.nodes],\n",
    "        mode='markers'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=400, height=400,\n",
    "    template='plotly_white',\n",
    "    title=f\"{clstr_ir5.slope:.2f}x+{clstr_ir5.intercept:.2f}; \"+\\\n",
    "          f\"r={clstr_ir5.rvalue:.2f}, p={clstr_ir5.pvalue:.2e}\",\n",
    "    xaxis={'title': 'degree'},\n",
    "    yaxis={'title': 'IR'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cavity vs outdegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cav_dim = dim_stats[dim_stats['type']=='real']\\\n",
    "    .sort_values(['mean'])\\\n",
    "    .reset_index()\\\n",
    "    .drop(['type','index'], axis=1)\\\n",
    "    .set_index('topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cav_dim.loc['anatomy']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cav_dim_means = [cav_dim.loc[t]['mean'] for t in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdegree.loc['Water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = [\n",
    "    np.mean([node_stats.loc[n].outdegree for n in networks[t].graph.nodes])\n",
    "    for t in topics\n",
    "]\n",
    "outdeg_dim = sp.stats.linregress(cav_dim_means, out)\n",
    "outdeg_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cav_dim_means,\n",
    "        y=out,\n",
    "        mode='markers', \n",
    "        name='Fields',\n",
    "        hovertext=topics\n",
    "    )\n",
    ")\n",
    "x = np.linspace(min(cav_dim_means), max(cav_dim_means), 1000)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x, y=outdeg_dim.slope*x + outdeg_dim.intercept,\n",
    "        mode='lines'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=400, height=400,\n",
    "    template='plotly_white',\n",
    "    title=f\"{outdeg_dim.slope:.2f}x+{outdeg_dim.intercept:.2f}\\n\"+\\\n",
    "          f\"r={outdeg_dim.rvalue:.2f}, p={outdeg_dim.pvalue:.3f}\",\n",
    "    xaxis={'title': 'mean cavity dimension'},\n",
    "    yaxis={'title': 'mean outdegree'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_fig = os.path.join('/','Users','harangju','Box Sync','Research',\n",
    "                        'my papers','wikipedia','results')\n",
    "path_plot = '4 fields'\n",
    "fig.write_image(os.path.join(path_fig, path_plot, 'cavity_dim_vs_out.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "deg = [\n",
    "    np.mean([node_stats.loc[n].degree for n in networks[t].graph.nodes])\n",
    "    for t in topics\n",
    "]\n",
    "deg_dim = sp.stats.linregress(cav_dim_means, deg)\n",
    "deg_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cav_dim_means,\n",
    "        y=deg,\n",
    "        mode='markers', \n",
    "        name='Fields',\n",
    "        hovertext=topics\n",
    "    )\n",
    ")\n",
    "x = np.linspace(min(cav_dim_means), max(cav_dim_means), 1000)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x, y=deg_dim.slope*x + deg_dim.intercept,\n",
    "        mode='lines'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=400, height=400,\n",
    "    template='plotly_white',\n",
    "    title=f\"{deg_dim.slope:.2f}x+{deg_dim.intercept:.2f}\\n\"+\\\n",
    "          f\"r={deg_dim.rvalue:.2f}, p={deg_dim.pvalue:.3f}\",\n",
    "    xaxis={'title': 'mean cavity dimension'},\n",
    "    yaxis={'title': 'mean degree'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fig = os.path.join('/','Users','harangju','Box Sync','Research',\n",
    "                        'my papers','wikipedia','results')\n",
    "path_plot = '4 fields'\n",
    "fig.write_image(os.path.join(path_fig, path_plot, 'cavity_dim_vs_deg.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu = [\n",
    "    np.mean([node_stats.loc[n].clustering for n in networks[t].graph.nodes])\n",
    "    for t in topics\n",
    "]\n",
    "clu_dim = sp.stats.linregress(cav_dim_means, clu)\n",
    "clu_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cav_dim_means,\n",
    "        y=clu,\n",
    "        mode='markers', \n",
    "        name='Fields',\n",
    "        hovertext=topics\n",
    "    )\n",
    ")\n",
    "x = np.linspace(min(cav_dim_means), max(cav_dim_means), 1000)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x, y=clu_dim.slope*x + clu_dim.intercept,\n",
    "        mode='lines'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=400, height=400,\n",
    "    template='plotly_white',\n",
    "    title=f\"{clu_dim.slope:.2f}x+{clu_dim.intercept:.2f}\\n\"+\\\n",
    "          f\"r={clu_dim.rvalue:.2f}, p={clu_dim.pvalue:.3f}\",\n",
    "    xaxis={'title': 'mean cavity dimension'},\n",
    "    yaxis={'title': 'mean clustering'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fig = os.path.join('/','Users','harangju','Box Sync','Research',\n",
    "                        'my papers','wikipedia','results')\n",
    "path_plot = '4 fields'\n",
    "fig.write_image(os.path.join(path_fig, path_plot, 'cavity_dim_vs_clustering.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node = 'Water'\n",
    "[big_net.graph.edges[node,t]['weight'] for t in big_net.graph.successors(node)][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weighted_outdegree = pd.DataFrame()\n",
    "for node in big_net.graph.nodes:\n",
    "    weighted_outdegree = pd.concat(\n",
    "        [\n",
    "            weighted_outdegree, \n",
    "            pd.DataFrame(\n",
    "                [[\n",
    "                    node,\n",
    "                    [big_net.graph.edges[node,t]['weight'] \n",
    "                     for t in big_net.graph.successors(node)]\n",
    "                ]],\n",
    "                columns=['node', 'weighted outdegree']\n",
    "            )\n",
    "        ],\n",
    "        ignore_index=True\n",
    "    )\n",
    "weighted_outdegree = weighted_outdegree.set_index('node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weighted_outdegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = topics[0]\n",
    "[\n",
    "    w \n",
    "    for n in networks[t].graph.nodes\n",
    "    for w in weighted_outdegree.loc[n]['weighted outdegree']\n",
    "][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wout = [\n",
    "    np.mean(\n",
    "        [\n",
    "            w\n",
    "            for n in networks[t].graph.nodes\n",
    "            for w in weighted_outdegree.loc[n]['weighted outdegree']\n",
    "        ]\n",
    "    )\n",
    "    for t in topics\n",
    "]\n",
    "weighted_outdeg_dim = sp.stats.linregress(cav_dim_means, wout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weighted_outdeg_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cav_dim_means,\n",
    "        y=wout,\n",
    "        mode='markers', \n",
    "        name='Fields',\n",
    "        hovertext=topics\n",
    "    )\n",
    ")\n",
    "x = np.linspace(min(cav_dim_means), max(cav_dim_means), 1000)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x, y=weighted_outdeg_dim.slope*x + weighted_outdeg_dim.intercept,\n",
    "        mode='lines'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=400, height=400,\n",
    "    template='plotly_white',\n",
    "    title=f\"{weighted_outdeg_dim.slope:.2f}x+{weighted_outdeg_dim.intercept:.2f}\\n\"+\\\n",
    "          f\"r={weighted_outdeg_dim.rvalue:.2f}, p={weighted_outdeg_dim.pvalue:.2f}\",\n",
    "    xaxis={'title': 'mean cavity dimension'},\n",
    "    yaxis={'title': 'mean weighted outdegree'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_fig = os.path.join('/','Users','harangju','Box Sync','Research',\n",
    "                        'my papers','wikipedia','results')\n",
    "path_plot = '4 fields'\n",
    "fig.write_image(os.path.join(path_fig, path_plot, 'cavity_dim_vs_wout.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wiki.Net.assign_communities(big_net.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "big_net.graph.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_saved = os.path.join('/','Users','harangju','Developer',\n",
    "                          'data','wiki','graphs','dated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "big_net.save_graph(os.path.join(path_saved,'big_network.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "big_net_sum = wiki.Net()\n",
    "communities = set(nx.get_node_attributes(big_net.graph, 'community').values())\n",
    "communities\n",
    "for community_a in communities:\n",
    "    for community_b in communities:\n",
    "        if community_a==community_b:\n",
    "            continue\n",
    "        nodes_a = []\n",
    "        nodes_b = []\n",
    "        for n in big_net.graph.nodes:\n",
    "            community_n = big_net.graph.nodes[n]['community']\n",
    "            if community_n==community_a:\n",
    "                nodes_a.append(n)\n",
    "            elif community_n==community_b:\n",
    "                nodes_b.append(n)\n",
    "        weight_a_b = 0\n",
    "        weight_b_a = 0\n",
    "        for node_a in nodes_a:\n",
    "            for node_b in nodes_b:\n",
    "                if node_b in big_net.graph[node_a]:\n",
    "                    weight_a_b += big_net.graph[node_a][node_b]['weight']\n",
    "                if node_a in big_net.graph[node_b]:\n",
    "                    weight_b_a += big_net.graph[node_b][node_a]['weight']\n",
    "        print((community_a, community_b),\n",
    "              (weight_a_b, weight_b_a))\n",
    "        big_net_sum.graph.add_edge(community_a, community_b,\n",
    "                                   weight=weight_a_b)\n",
    "        big_net_sum.graph.add_edge(community_b, community_a,\n",
    "                                   weight=weight_b_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "big_net_sum.save_graph(os.path.join(path_saved,\n",
    "                                    'big_network_summary.pickle'))\n",
    "big_net_sum.save_graph(os.path.join(path_saved,\n",
    "                                    'big_network_summary.gexf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'Commercial law' in networks['law'].graph,\\\n",
    "'Null' in networks['law'].graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sum([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "big_net_topics = wiki.Net()\n",
    "for i, topic_a in enumerate(topics):\n",
    "    print(i, len(topics), topic_a)\n",
    "    nodes_a = [n for n in big_net.graph.nodes\n",
    "               if n in networks[topic_a].graph]\n",
    "    for topic_b in topics:\n",
    "        if topic_a==topic_b:\n",
    "            continue\n",
    "        nodes_b = [n for n in big_net.graph.nodes\n",
    "                   if n in networks[topic_b].graph]\n",
    "        weight_a_b = []\n",
    "        weight_b_a = []\n",
    "        for node_a in nodes_a:\n",
    "            for node_b in nodes_b:\n",
    "                if node_b in big_net.graph[node_a]:\n",
    "                    weight_a_b += [big_net.graph[node_a][node_b]['weight']]\n",
    "                if node_a in big_net.graph[node_b]:\n",
    "                    weight_b_a += [big_net.graph[node_b][node_a]['weight']]\n",
    "        big_net_topics.graph.add_edge(topic_a, topic_b,\n",
    "                                      weight_sum=np.sum(weight_a_b),\n",
    "                                      weight_mean=np.mean(weight_a_b))\n",
    "        big_net_topics.graph.add_edge(topic_b, topic_a,\n",
    "                                      weight_sum=np.sum(weight_b_a),\n",
    "                                      weight_mean=np.mean(weight_b_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for a, b in big_net_topics.graph.edges:\n",
    "    if math.isnan(big_net_topics.graph.edges[a,b]['weight_mean']):\n",
    "        big_net_topics.graph.add_edge(a, b, weight_mean=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "big_net_topics.save_graph(os.path.join(path_saved,\n",
    "                                       'big_network_topics.pickle'))\n",
    "big_net_topics.save_graph(os.path.join(path_saved,\n",
    "                                       'big_network_topics.gexf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "big_net_topics = wiki.Net()\n",
    "big_net_topics.load_graph(os.path.join(path_saved, 'big_network_topics.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A_topics_mean = nx.adjacency_matrix(big_net_topics.graph, weight='weight_mean').transpose()\n",
    "val, vec = sp.sparse.linalg.eigs(A_topics_mean)\n",
    "A_topics_mean = A_topics_mean / (1 + np.max(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = A_topics_mean**1\n",
    "fig = px.imshow(data.toarray().astype(np.float64),\n",
    "                x=topics, y=topics)\n",
    "fig.update_layout(width=950, height=950,\n",
    "                  coloraxis = {'colorscale':'Greens'},\n",
    "                  title='Topic network (weights averaged across topics)',\n",
    "                  xaxis={'side': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path_fig = os.path.join('/','Users','harangju','Box Sync','Research','my papers','wikipedia','results')\n",
    "# path_plot = '4 fields'\n",
    "# fig.write_image(os.path.join(path_fig, path_plot, 'communicability_avg_across_topics.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic^T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T = 10\n",
    "data = A_topics_mean**T\n",
    "fig = px.imshow(data.toarray().astype(np.float64),\n",
    "                x=topics, y=topics)\n",
    "fig.update_layout(width=950, height=950,\n",
    "                  coloraxis = {'colorscale':'Greens'},\n",
    "                  title=f\"Topic network ^{T}\",\n",
    "                  xaxis={'side': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_fig = os.path.join('/','Users','harangju','Box Sync','Research','my papers','wikipedia','results')\n",
    "path_plot = '4 fields'\n",
    "fig.write_image(os.path.join(path_fig, path_plot, 'topic_network_power_10.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flow = pd.DataFrame()\n",
    "for t in range(1,T):\n",
    "    data = (A_topics_mean**t).toarray().astype(np.float)\n",
    "    flow = pd.concat([flow, pd.DataFrame([np.sum(data, axis=1) - np.sum(data, axis=0)],\n",
    "                                         columns=topics)],\n",
    "                     ignore_index=True)\n",
    "flow = flow.transpose().sort_values(0)\n",
    "flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for t in flow.index:\n",
    "    fig.add_trace(go.Scatter(x=flow.columns,\n",
    "                             y=flow.loc[t].values,\n",
    "                             mode='lines',\n",
    "                             name=t))\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cavity vs topic controllability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = dim_stats[dim_stats['type']=='real']\\\n",
    "    .sort_values(['mean'])\\\n",
    "    .reset_index()\\\n",
    "    .drop(['type','index'], axis=1)\\\n",
    "    .set_index('topic')\n",
    "x = np.array([x.loc[t]['mean'] for t in topics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CG, OG = gramians(A_topics_mean, 10)\n",
    "y = CG.diagonal().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = len(topics)\n",
    "pd.DataFrame({'topic': topics, 'controllability (t=10)': y})\\\n",
    "    .sort_values('controllability (t=10)')\\\n",
    "    .reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_y = sp.stats.linregress(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y,\n",
    "                         mode='markers', \n",
    "                         name='Fields',\n",
    "                         hovertext=topics))\n",
    "fig.add_trace(go.Scatter(x=np.linspace(min(x), max(x), num=100),\n",
    "                         y=np.linspace(min(x), max(x), num=100) * x_y[0] + x_y[1],\n",
    "                         mode='lines',\n",
    "                         name=f\"R^2={x_y[2]:.2f}, p={x_y[3]:.2f}\"))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  yaxis={'title': 'Topic controllability'},\n",
    "                  xaxis={'title': 'Mean cavity dimension'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path_fig = os.path.join('/','Users','harangju','Box Sync','Research','my papers','wikipedia','results')\n",
    "# path_plot = '4 fields'\n",
    "# fig.write_image(os.path.join(path_fig, path_plot, 'cavity_dim_vs_topic_ctrb.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communicability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "communicability_topics_mean = sp.sparse.linalg.expm(A_topics_mean).toarray().astype(np.float64)\n",
    "communicability_topics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heat = communicability_topics_mean - \\\n",
    "    np.multiply(communicability_topics_mean, np.eye(communicability_topics_mean.shape[0]))\n",
    "\n",
    "fig = px.imshow(heat, x=topics, y=topics)\n",
    "fig.update_layout(width=950, height=950,\n",
    "                  coloraxis = {'colorscale':'Greens'},\n",
    "                  title='Communicability (weights averaged across topics)',\n",
    "                  xaxis={'side': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path_fig = os.path.join('/','Users','harangju','Box Sync','Research','my papers','wikipedia','results')\n",
    "# path_plot = '4 fields'\n",
    "# fig.write_image(os.path.join(path_fig, path_plot, 'communicability_avg_across_topics.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A_topics_sum = nx.adjacency_matrix(big_net_topics.graph, weight='weight_sum').transpose()\n",
    "val, vec = sp.sparse.linalg.eigs(A_topics_sum)\n",
    "A_topics_sum = A_topics_sum / (1 + val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "communicability_topics_sum = sp.sparse.linalg.expm(A_topics_sum).toarray().astype(np.float64)\n",
    "communicability_topics_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.imshow(communicability_topics_sum - \\\n",
    "                np.multiply(communicability_topics_sum, np.eye(communicability_topics_sum.shape[0])),\n",
    "                x=topics, y=topics)\n",
    "fig.update_layout(width=1000, height=1000,\n",
    "                  coloraxis = {'colorscale':'Teal'},\n",
    "                  title='Communicability (weights summed across topics)',\n",
    "                  xaxis={'side': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def communicability_by_topics(A, networks):\n",
    "    for topic_1, network_1 in networks.items():\n",
    "        for topic_2, network_2 in networks.items():\n",
    "            if topic_1==topic_2:\n",
    "                pass\n",
    "            else:\n",
    "                pass\n",
    "    return sp.sparse.linalg.expm(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eigval, eigvec = sp.sparse.linalg.eigs(A.transpose())\n",
    "# G = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eigvec*eigvec.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A.shape[0]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awards\n",
    "\n",
    "* [Nobel prize](https://en.wikipedia.org/wiki/List_of_Nobel_laureates)\n",
    "* [Fields medal](https://en.wikipedia.org/wiki/Fields_Medal)\n",
    "* [Turing award](https://en.wikipedia.org/wiki/Turing_Award)\n",
    "* [National Medal of Science](https://en.wikipedia.org/wiki/List_of_National_Medal_of_Science_laureates)\n",
    "    * No because only American"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_base = '/Users/harangju/Developer/data/wiki/dumps/'\n",
    "name_xml = 'enwiki-20190801-pages-articles-multistream.xml.bz2'\n",
    "name_index = 'enwiki-20190801-pages-articles-multistream-index.txt.bz2'\n",
    "path_xml = path_base + name_xml\n",
    "path_index = path_base + name_index\n",
    "dump = wiki.Dump(path_xml, path_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nobel prizes\n",
    "\n",
    "* [Physics](https://en.wikipedia.org/wiki/List_of_Nobel_laureates_in_Physics)\n",
    "* [Chemistry](https://en.wikipedia.org/wiki/List_of_Nobel_laureates_in_Chemistry)\n",
    "* [Physiology or Medicine](https://en.wikipedia.org/wiki/List_of_Nobel_laureates_in_Physiology_or_Medicine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump.load_page('List of Nobel laureates in Physics');\n",
    "laureate_section = [s for s in dump.page.get_sections() if 'Laureates' in s[:100]][0]\n",
    "laureate_section[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_links = [\n",
    "    link.title\n",
    "    for link in laureate_section.filter_wikilinks() if 'px' not in link\n",
    "]\n",
    "physics_links[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump.load_page('Kip Thorne')\n",
    "dump.page.filter_templates('Infobox')[0][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump.load_page('Radiation')[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump.load_page('List of Nobel laureates in Chemistry');\n",
    "laureate_section = [s for s in dump.page.get_sections() if 'Laureates' in s[:100]][0]\n",
    "laureate_section[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemistry_links = [\n",
    "    link.title\n",
    "    for link in laureate_section.filter_wikilinks() if 'px' not in link\n",
    "]\n",
    "chemistry_links[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump.load_page('List of Nobel laureates in Physiology or Medicine');\n",
    "laureate_section = [s for s in dump.page.get_sections() if 'Laureates' in s[:100]][0]\n",
    "laureate_section[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicine_links = [\n",
    "    link.title\n",
    "    for link in laureate_section.filter_wikilinks() if 'px' not in link\n",
    "]\n",
    "medicine_links[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_links = physics_links + chemistry_links + medicine_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fields medal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turing award"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(big_net.graph.nodes), list(big_net.graph.nodes)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_nodes = [\n",
    "    node\n",
    "    for node in big_net.graph.nodes\n",
    "    if node.upper() in (link.upper() for link in nobel_links)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_nodes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nobel_nodes), len(nobel_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nobel_nodes = list(set(big_net.graph.nodes) - set(nobel_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impulse response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.colors.qualitative.Plotly[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_grams = grams.loc[nobel_nodes]['CG_5'].values.astype(np.float32)\n",
    "non_nobel_grams = grams.loc[\n",
    "    set(big_net.graph.nodes)-set(nobel_nodes)\n",
    "]['CG_5'].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Box(\n",
    "        x=nobel_grams,\n",
    "#         boxpoints='all', jitter=0.3,\n",
    "        marker_color=px.colors.qualitative.Plotly[0],\n",
    "        name='Nobel prize-winning nodes'\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Box(\n",
    "        x=non_nobel_grams,\n",
    "        marker_color=px.colors.qualitative.Plotly[0],\n",
    "        name='non-Nobel prize-winning nodes'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    height=300,\n",
    "    template='plotly_white',\n",
    "    yaxis={'title': ''},\n",
    "    xaxis={'title': 'impulse response'},\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.var(nobel_grams), np.var(non_nobel_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.ttest_ind(nobel_grams, non_nobel_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp.stats.ttest_ind(nobel_grams, non_nobel_grams, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.mannwhitneyu(\n",
    "    nobel_grams, non_nobel_grams,\n",
    "    use_continuity=True, alternative='two-sided'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = sp.stats.ks_2samp(\n",
    "    nobel_grams, non_nobel_grams, alternative='two-sided'\n",
    ")\n",
    "ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = np.concatenate((nobel_grams, non_nobel_grams))\n",
    "ir_range = np.arange(np.min(ir), np.max(ir), 0.01)\n",
    "cum_freq_nobel = np.zeros(ir_range.size)\n",
    "cum_freq_non_nobel = np.zeros(ir_range.size)\n",
    "for i, ir in enumerate(ir_range):\n",
    "    cum_freq_nobel[i] = np.sum(nobel_grams<ir) / nobel_grams.size\n",
    "    cum_freq_non_nobel[i] = np.sum(non_nobel_grams<ir) / non_nobel_grams.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=ir_range,\n",
    "        y=cum_freq_nobel,\n",
    "        name='Nobel'\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=ir_range,\n",
    "        y=cum_freq_non_nobel,\n",
    "        name='non-Nobel'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=400, height=400,\n",
    "    template='plotly_white',\n",
    "    yaxis={'title': 'cumulative frequency'},\n",
    "    xaxis={'title': 'impulse response',\n",
    "           'type': 'log'},\n",
    "    legend={'x': .5, 'y':.8}\n",
    ")\n",
    "fig.add_annotation(\n",
    "    x=.2, y=.5, text='IR higher here', showarrow=False\n",
    ")\n",
    "fig.add_annotation(\n",
    "    x=.2, y=.4, text=f\"KS={ks.statistic:.2f}, p={ks.pvalue:.1e}\", showarrow=False\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(path_fig, path_plot, 'ir_cum_freq.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cavity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes = pd.concat(\n",
    "    [\n",
    "        network.barcodes.assign(topic=topic)\\\n",
    "            .assign(type='real')\\\n",
    "        .assign(null=0)\n",
    "        for topic, network in networks.items()\n",
    "    ],\n",
    "    ignore_index=True,\n",
    "    sort=False\n",
    ")\n",
    "barcodes = barcodes[barcodes.lifetime!=0]\n",
    "barcodes = barcodes.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['birth simplex', 'death simplex', 'birth nodes', 'death nodes', 'homology nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(barcodes.index) - set(range(len(barcodes.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavity_participation = pd.DataFrame(columns=keys)\n",
    "for node in big_net.graph.nodes:\n",
    "    cavity_participation.loc[node] = 0\n",
    "cavity_participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavities = {key: [] for key in keys}\n",
    "for i, row in barcodes.iterrows():\n",
    "    for key in keys:\n",
    "        cavities[key] += row[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavity_counts = {\n",
    "    key: {\n",
    "        node: cavities[key].count(node)\n",
    "        for node in set(cavities[key])\n",
    "    }\n",
    "    for key in keys\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavity_participation = pd.DataFrame(cavity_counts).fillna(0)\n",
    "cavity_participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in big_net.graph.nodes:\n",
    "    if node not in cavity_participation.index:\n",
    "        cavity_participation.loc[node] = 0\n",
    "cavity_participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(big_net.graph.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_analysis = os.path.join(\n",
    "    '/','Users','harangju','Developer','data','wiki','analysis'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    cavity_participation,\n",
    "    open(os.path.join(path_analysis, 'cavity_participation.pickle'), 'wb')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_analysis = os.path.join(\n",
    "    '/','Users','harangju','Developer','data','wiki','analysis'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "cavity_participation = pickle.load(\n",
    "    open(os.path.join(path_analysis, 'cavity_participation.pickle'), 'rb')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_plot = '4 fields'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keys = [\n",
    "    'birth simplex', 'death simplex', 'birth nodes', 'death nodes', 'homology nodes'\n",
    "]\n",
    "for key in keys:\n",
    "    fig = go.Figure()\n",
    "    nobel = cavity_participation.loc[nobel_nodes][key].values\n",
    "    non_nobel = cavity_participation.loc[non_nobel_nodes][key].values\n",
    "    fig.add_trace(go.Box(x=nobel, name='Nobel'))\n",
    "    fig.add_trace(go.Box(x=non_nobel, name='non-Nobel'))\n",
    "    fig.update_layout(\n",
    "        width=600, height=300,\n",
    "        template='plotly_white',\n",
    "        xaxis={'title': f\"participation in {key}\"},\n",
    "        yaxis={'title': ''}\n",
    "    )\n",
    "    ks = sp.stats.ks_2samp(nobel, non_nobel, alternative='two-sided')\n",
    "    fig.add_annotation(\n",
    "        x=0, y=-1, text=f\"KS={ks.statistic:.2f}, p={ks.pvalue:.1e}\", showarrow=False\n",
    "    )\n",
    "    fig.show()\n",
    "    fig.write_image(os.path.join(path_fig, path_plot, f\"participation_{key}.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    fig = go.Figure()\n",
    "    nobel = cavity_participation.loc[nobel_nodes][key].values\n",
    "    non_nobel = cavity_participation.loc[non_nobel_nodes][key].values\n",
    "    xs = np.concatenate([nobel, non_nobel])\n",
    "    x_range = np.arange(np.min(xs), np.max(xs), (np.max(xs)-np.min(xs))/100.)\n",
    "    cum_freq_nobel = np.zeros(x_range.size)\n",
    "    cum_freq_non_nobel = np.zeros(x_range.size)\n",
    "    for i, x in enumerate(x_range):\n",
    "        cum_freq_nobel[i] = np.sum(nobel<x) / nobel.size\n",
    "        cum_freq_non_nobel[i] = np.sum(non_nobel<x) / non_nobel.size\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_range,\n",
    "            y=cum_freq_nobel,\n",
    "            name='Nobel'\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_range,\n",
    "            y=cum_freq_non_nobel,\n",
    "            name='non-Nobel'\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        width=400, height=400,\n",
    "        template='plotly_white',\n",
    "        yaxis={'title': 'cumulative frequency'},\n",
    "        xaxis={'title': key},#, 'type': 'log'},\n",
    "        legend={'x': .5, 'y':.8}\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=(x_range[-1]-x_range[0])/2., y=.5, text='higher here', showarrow=False\n",
    "    )\n",
    "    ks = sp.stats.ks_2samp(\n",
    "        nobel, non_nobel, alternative='two-sided'\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=(x_range[-1]-x_range[0])/2., y=.4, xref='x', yref='y',\n",
    "        text=f\"KS={ks.statistic:.2f}, p={ks.pvalue:.1e}\", showarrow=False\n",
    "    )\n",
    "#     fig.update_xaxes(range=[0, np.log(np.max(xs))/np.log(10)])\n",
    "    fig.show()\n",
    "    fig.write_image(os.path.join(path_fig, path_plot, f\"participation_cdf_{key}.pdf\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "221.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
