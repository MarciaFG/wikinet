{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network measures\n",
    "\n",
    "### Local structures\n",
    "\n",
    "**Indegree**\n",
    "This is mostly a function of how Wikipedians revised the document and should largely be uniform across pages. The large values are likely pages with 'lists' of links.\n",
    "\n",
    "**Outdegree**\n",
    "This is 1st-order measure of an idea's influence.\n",
    "\n",
    "### Mesoscale structures\n",
    "\n",
    "**Clustering**\n",
    "These look equally clustered among the topics.\n",
    "\n",
    "**Centrality**\n",
    "This reveals the distribution of sources of ideas within a field.\n",
    "\n",
    "**Path lengths**\n",
    "\n",
    "**Rich-club coefficient**\n",
    "\n",
    "**Modularity**\n",
    "\n",
    "**Controllability**\n",
    "This is an nth-order measure of influence.\n",
    "\n",
    "**Observability**\n",
    "This is an nth-order measure of the inverse of influence.\n",
    "\n",
    "**Coreness**\n",
    "It seems that the more focused a topic is on a subtopic, the stronger the coreness. For example, genetics is heavily focused on DNA, and so it has high coreness. At the same time, in the field of economics, the concept of \"economics\" has high degree. Yet, it has low coreness because the field itself is heterogeneous, with major subfields such as \"macroeconomics\" and \"microeconomics\".\n",
    "\n",
    "**Characteristic path length**\n",
    "I'm not sure what path length reveals. Perhaps it is a measure of the heterogeneity in research? It describes how far one idea is to another, topologically. Cognitive science and earth science have ideas that are far away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..', 'module'))\n",
    "import wiki\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['anatomy', 'biochemistry', 'cognitive science', 'evolutionary biology',\n",
    "          'genetics', 'immunology', 'molecular biology', 'chemistry', 'biophysics',\n",
    "          'energy', 'optics', 'earth science', 'geology', 'meteorology',\n",
    "          'philosophy of language', 'philosophy of law', 'philosophy of mind',\n",
    "          'philosophy of science', 'economics', 'accounting', 'education',\n",
    "          'linguistics', 'law', 'psychology', 'sociology', 'electronics',\n",
    "          'software engineering', 'robotics']#, 'physics', 'mathematics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved = '/Users/harangju/Developer/data/wiki/graphs/dated/'\n",
    "networks = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    networks[topic] = wiki.Net()\n",
    "    networks[topic].load_graph(path_saved + topic + '.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved = '/Users/harangju/Developer/data/wiki/graphs/null-target/'\n",
    "num_nulls = 2\n",
    "null_targets = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    null_targets[topic] = []\n",
    "    for i in range(num_nulls):\n",
    "        network = wiki.Net()\n",
    "        network.load_graph(path_saved + topic + '-null-' + str(i) + '.pickle')\n",
    "        null_targets[topic].append(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run analysis\n",
    "\n",
    "**NOTE:** Skip section if loading stats.\n",
    "\n",
    "### Basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bct\n",
    "from networkx.algorithms.cluster import clustering\n",
    "from networkx.algorithms import betweenness_centrality\n",
    "from networkx.convert_matrix import to_numpy_array\n",
    "pd.options.display.max_rows = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = {'indegree': lambda g: [x[1] for x in g.in_degree],\n",
    "            'outdegree': lambda g: [x[1] for x in g.out_degree],\n",
    "            'clustering': lambda g: list(clustering(g).values()),\n",
    "            'centrality': lambda g: list(betweenness_centrality(g).values()),\n",
    "            'path-length': lambda g: [y for x in list(nx.shortest_path_length(g))\n",
    "                                      for y in list(x[1].values())],\n",
    "            'char-path-length': lambda g: bct.charpath(to_numpy_array(g))[0],\n",
    "            'modularity': lambda g: g.graph['modularity'],\n",
    "            'coreness': lambda g: g.graph['coreness']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks['anatomy'].graph.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['topic','measure','value'])\n",
    "for topic, network in networks.items():\n",
    "    print(topic, end=' ')\n",
    "    df = pd.concat([df] +\n",
    "                   [pd.DataFrame([[topic, measure, func(network.graph)]],\n",
    "                                 columns=['topic','measure','value'])\n",
    "                    for measure, func in measures.items()],\n",
    "                   ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic, null_networks in null_targets.items():\n",
    "    print(topic, end=' ')\n",
    "    for network in null_networks:\n",
    "        df = pd.concat([df] + \n",
    "                       [pd.DataFrame([[topic, measure+'-null', func(network.graph)]],\n",
    "                                     columns=['topic','measure','value'])\n",
    "                        for measure, func in measures.items()],\n",
    "                       ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df_expand = df.value\\\n",
    "              .apply(pd.Series)\\\n",
    "              .merge(df, left_index=True, right_index=True)\\\n",
    "              .drop('value', axis=1)\\\n",
    "              .melt(id_vars=['topic','measure'])\\\n",
    "              .drop('variable', axis=1)\\\n",
    "              .dropna()\n",
    "df_expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump((df, df_expand),\n",
    "            open('/Users/harangju/Developer/data/wiki/analysis/stats.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "comm, df, df_expand = pickle.load(\n",
    "    open('/Users/harangju/Developer/data/wiki/analysis/stats.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expand.groupby(['topic','measure'])\\\n",
    "         .mean()\\\n",
    "         .reset_index()\\\n",
    "         .pivot(index='topic',columns='measure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot\n",
    "\n",
    "* nice plots [seaborn](https://seaborn.pydata.org/examples/index.html)\n",
    "* interactive [Bokeh](https://bokeh.pydata.org/en/latest/docs/gallery.html#gallery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style='whitegrid', font_scale=2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 12\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_dir = None\n",
    "for stat in ['indegree', 'outdegree', 'clustering', 'centrality', 'path-length']:\n",
    "    f, ax = plt.subplots(figsize=(30, 6))\n",
    "    sns.violinplot(data=df_expand[(df_expand.measure==stat) |\\\n",
    "                                  (df_expand.measure==stat+'-null')],\n",
    "                   x='topic', y='value', hue='measure', split=True)\n",
    "    plt.xticks(np.arange(len(topics)), topics, rotation='vertical')\n",
    "    plt.ylabel(stat)\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()\n",
    "    if save_dir:\n",
    "        plt.savefig(save_dir, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = None\n",
    "for stat in ['coreness', 'modularity', 'char-path-length']:\n",
    "    f, ax = plt.subplots(figsize=(30, 6))\n",
    "    sns.scatterplot(data=df_expand[(df_expand.measure==stat) |\\\n",
    "                                   (df_expand.measure==stat+'-null')],\n",
    "                    x='topic', y='value', hue='measure')\n",
    "    plt.xticks(np.arange(len(topics)), topics, rotation='vertical')\n",
    "    plt.ylabel(stat)\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()\n",
    "    if save_dir:\n",
    "        plt.savefig(path_saved + stat, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = None\n",
    "f, axs = plt.subplots(ncols=2, figsize=(10,5))\n",
    "f.tight_layout()\n",
    "for i, stat in enumerate(['coreness', 'modularity']):\n",
    "    x = df_expand[df_expand.measure==stat+'-null']\\\n",
    "        .groupby('topic').mean().value.values\n",
    "    y = df_expand[df_expand.measure==stat].value.values\n",
    "    sns.scatterplot(x=x, y=y, ax=axs[i], marker='x')\n",
    "    z = np.concatenate((x,y))\n",
    "    sns.lineplot(x=[min(z), max(z)], y=[min(z), max(z)], ax=axs[i])\n",
    "    axs[i].set_title(stat)\n",
    "    if save_dir:\n",
    "        plt.savefig(path_saved + stat, dpi=300)\n",
    "axs[0].set(xlabel='null', ylabel='real', aspect='equal')\n",
    "axs[1].set(xlabel='null', aspect='equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures in growing networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comm_t = pd.DataFrame()\n",
    "for topic, network in networks.items():\n",
    "    print(topic, end=' ')\n",
    "    comm_t = pd.concat([comm_t] +\n",
    "                       [pd.DataFrame([[topic,\n",
    "                                       node,\n",
    "                                       network.graph.nodes[node]['year'],\n",
    "                                       network.graph.nodes[node]['community'],\n",
    "                                       network.graph.nodes[node]['core'],\n",
    "                                       1]],\n",
    "                                     columns=['topic','node','year',\n",
    "                                              'comm','core','count'])\n",
    "                        for node in network.graph.nodes],\n",
    "                       ignore_index=True)\n",
    "comm_t = comm_t.merge(comm_t.groupby(['topic','comm'])['count'].sum(),\n",
    "                      on=['topic','comm'],\n",
    "                      suffixes=('','_topic_comm'))\\\n",
    "               .merge(comm_t.groupby(['topic','core'])['count'].sum(),\n",
    "                      on=['topic','core'],\n",
    "                      suffixes=('','_topic_core'))\\\n",
    "               .sort_values(by=['topic','year'])\\\n",
    "               .reset_index(drop=True)\n",
    "comm_t['comm_count'] = comm_t.groupby(['topic','comm'])['count']\\\n",
    "                             .transform(pd.Series.cumsum)\n",
    "comm_t['core_count'] = comm_t.groupby(['topic','core'])['count']\\\n",
    "                             .transform(pd.Series.cumsum)\n",
    "comm_t['comm_frac'] = comm_t['comm_count']/comm_t['count_topic_comm']\n",
    "comm_t['core_frac'] = comm_t['core_count']/comm_t['count_topic_core']\n",
    "comm_t = comm_t.drop(['count','count_topic_comm','count_topic_core'], axis=1)\n",
    "comm_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Growth in core-periphery & modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for topic in networks.keys():\n",
    "    plt.figure(figsize=(20,6))\n",
    "    sns.lineplot(x='year', y='comm_count', hue='comm',\n",
    "                 data=comm_t[comm_t.topic==topic])\n",
    "    plt.title(topic)\n",
    "    plt.xlim((0,2030))\n",
    "    plt.figure(figsize=(20,6))\n",
    "    sns.lineplot(x='year', y='comm_frac', hue='comm',\n",
    "                 data=comm_t[comm_t.topic==topic])\n",
    "    plt.xlim((0,2030))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for topic in networks.keys():\n",
    "    fig = plt.figure(figsize=(20,6))\n",
    "    sns.lineplot(x='year', y='core_count', hue='core',\n",
    "                 data=comm_t[comm_t.topic==topic])\n",
    "    plt.title(topic)\n",
    "    fig = plt.figure(figsize=(20,6))\n",
    "    sns.lineplot(x='year', y='core_frac', hue='core',\n",
    "                 data=comm_t[comm_t.topic==topic])\n",
    "    plt.title(topic)\n",
    "    plt.xlim((0,2030))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birth: core vs. periphery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "birth = pd.concat([pd.DataFrame([[comm_t.iloc[i].topic,\n",
    "                                  comm_t.iloc[i].node,\n",
    "                                  comm_t.iloc[i].year,\n",
    "                                  [c for c in \n",
    "                                   list(networks[comm_t.iloc[i].topic]\\\n",
    "                                        .graph.successors(comm_t.iloc[i].node)) + \n",
    "                                   list(networks[comm_t.iloc[i].topic]\\\n",
    "                                        .graph.predecessors(comm_t.iloc[i].node))\n",
    "                                   if networks[comm_t.iloc[i].topic].graph.nodes[c]['core']]\n",
    "                                 ]],\n",
    "                                columns=['topic','periphery','year','cores'])\n",
    "                   for i in range(len(comm_t.index))\n",
    "                   if not comm_t.iloc[i].core],\n",
    "                  ignore_index=True)\n",
    "birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "birth_exp = birth.cores.apply(pd.Series)\\\n",
    "                 .merge(birth, left_index=True, right_index=True)\\\n",
    "                 .drop(['cores'], axis=1)\\\n",
    "                 .melt(id_vars=['topic','periphery','year'], value_name='core')\\\n",
    "                 .drop('variable', axis=1)\\\n",
    "                 .dropna()\\\n",
    "                 .sort_values(by=['topic','year', 'periphery'])\\\n",
    "                 .reset_index(drop=True)\n",
    "birth_exp['core_year'] = [networks[birth_exp.iloc[i].topic].graph\\\n",
    "                          .nodes[birth_exp.iloc[i].core]['year']\n",
    "                          for i in range(len(birth_exp.index))]\n",
    "birth_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for topic in networks.keys():\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    ax = sns.scatterplot(x='year', y='core_year', marker='.',\n",
    "                         data=birth_exp[birth_exp.topic==topic])\n",
    "    ax.set(xlabel='periphery', ylabel='core', aspect='equal')\n",
    "    z = np.concatenate((birth_exp[birth_exp.topic==topic].year.values,\n",
    "                        birth_exp[birth_exp.topic==topic].core_year.values))\n",
    "    sns.lineplot(x=[min(z), max(z)], y=[min(z), max(z)], ax=ax)\n",
    "    plt.title(topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
