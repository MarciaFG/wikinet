{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network growth\n",
    "\n",
    "1. Search \"History\" in section headings.\n",
    "2. Find a list of years.\n",
    "3. Use the first one as when the birth year of the idea.\n",
    "4. If no \"History\" section, then look backwards in the graph to a page that does, and use that.\n",
    "\n",
    "#### Visualization\n",
    "* Use ~~[bokeh](https://bokeh.pydata.org/en/latest/docs/user_guide/graph.html)~~ ~~[webweb](https://webwebpage.github.io/)~~ [d3](https://observablehq.com/@d3/force-directed-graph).\n",
    "* Use slider to show growth in network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label with years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "path_saved = '/Users/harangju/Box Sync/Research/my papers/wikipedia paper/data/prelim data/'\n",
    "# natural & physical sciences\n",
    "topics = ['anatomy', 'biochemistry', 'cognitive science', 'evolutionary biology',\n",
    "          'genetics', 'immunology', 'molecular biology']\n",
    "topics += ['chemistry', 'biophysics', 'energy', 'optics', \n",
    "           'earth science', 'geology', 'meteorology']\n",
    "# philosophy\n",
    "# topics += []\n",
    "topics += ['philosophy of language', 'philosophy of law', \n",
    "           'philosophy of mind', 'philosophy of science']\n",
    "# social sciences\n",
    "topics += ['economics', 'accounting', 'education', 'linguistics', 'law', 'psychology', 'sociology']\n",
    "# technology & applied sciences\n",
    "topics += ['electronics', 'software engineering', 'robotics']\n",
    "topics += ['physics']\n",
    "\n",
    "graphs = {}\n",
    "for topic in topics:\n",
    "    graphs[topic] = nx.read_gexf(path_saved + topic + '_d2.gexf')\n",
    "graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wiki\n",
    "\n",
    "path_base = '/Users/harangju/Developer/data/wiki/'\n",
    "name_xml = 'enwiki-20190801-pages-articles-multistream.xml.bz2'\n",
    "name_index = 'enwiki-20190801-pages-articles-multistream-index.txt.bz2'\n",
    "path_xml = path_base + name_xml\n",
    "path_index = path_base + name_index\n",
    "dump = wiki.Dump(path_xml, path_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_graphs = {'robotics': graphs['robotics']}\n",
    "for topic, graph in graphs.items():\n",
    "    print('Topic: ' + topic)\n",
    "    for node in graph.nodes:\n",
    "        dump.load_page(node)\n",
    "        graph.nodes[node]['year'] = dump.years[0] if len(dump.years)>0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs['robotics'].nodes['Robotics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in nodes without years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_empty_nodes(graph, full_parents=True):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        whether at least 1 empty node was filled\n",
    "    \"\"\"\n",
    "    empty_nodes = [n for n in graph.nodes if not graph.nodes[n]['year']]\n",
    "    for node in empty_nodes:\n",
    "        years = [graph.nodes[p]['year'] for p in graph.predecessors(node)]\n",
    "        if not years:\n",
    "            continue\n",
    "        if full_parents:\n",
    "            if [] not in years:\n",
    "                graph.nodes[node]['year'] = max(years)\n",
    "                return True\n",
    "        else:\n",
    "            years_filtered = [y for y in years if y]\n",
    "            if years_filtered:\n",
    "                graph.nodes[node]['year'] = max(years_filtered)\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_graphs = {'biochemistry': graphs['biochemistry']}\n",
    "for topic, graph in _graphs.items():\n",
    "    nodes = graph.nodes\n",
    "    print('Filling in nodes with full parents...')\n",
    "    nodes_filled = True\n",
    "    while nodes_filled:\n",
    "        nodes_filled = fill_empty_nodes(graph, full_parents=True)\n",
    "    print('Filling in nodes without full parents...')\n",
    "    nodes_filled = True\n",
    "    while nodes_filled:\n",
    "        nodes_filled = fill_empty_nodes(graph, full_parents=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic, graph in _graphs.items():\n",
    "    path_save = path_base + 'graphs/dated_' + 'filled_' + topic + '.gexf'\n",
    "    nx.write_gexf(graphs[topic], path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['biochemistry']\n",
    "path_base = '/Users/harangju/Developer/data/wiki/graphs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'biochemistry': <networkx.classes.digraph.DiGraph at 0x106a4cf90>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "graphs = {}\n",
    "for topic in topics:\n",
    "    graphs[topic] = nx.read_gexf(path_base + 'dated_filled_' + topic + '.gexf')\n",
    "graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize growth\n",
    "\n",
    "* gephi [tutorial](https://seinecle.github.io/gephi-tutorials/generated-html/converting-a-network-with-dates-into-dynamic.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clique community growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cliques = nx.enumerate_all_cliques(nx.Graph(graphs['biochemistry']))\n",
    "cliques = nx.find_cliques(nx.Graph(graphs['biochemistry']))\n",
    "list(cliques)[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistent homology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
